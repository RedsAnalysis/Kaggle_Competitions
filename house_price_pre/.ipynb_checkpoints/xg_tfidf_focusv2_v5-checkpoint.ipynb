{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d873fc5-79e3-41d0-9907-da9cd99a809b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n",
      "Raw data loaded successfully.\n",
      "Setup complete.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# BLOCK 1: SETUP, IMPORTS, AND DATA LOADING\n",
    "# =============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "\n",
    "# --- Library Imports ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "\n",
    "print(\"Libraries imported successfully.\")\n",
    "\n",
    "# --- Helper Function for Winkler Score ---\n",
    "def winkler_score(y_true, lower, upper, alpha=0.1, return_coverage=False):\n",
    "    width = upper - lower\n",
    "    penalty_lower = np.where(y_true < lower, (2 / alpha) * (lower - y_true), 0)\n",
    "    penalty_upper = np.where(y_true > upper, (2 / alpha) * (y_true - upper), 0)\n",
    "    score = width + penalty_lower + penalty_upper\n",
    "    if return_coverage:\n",
    "        coverage = np.mean((y_true >= lower) & (y_true <= upper))\n",
    "        return np.mean(score), coverage\n",
    "    return np.mean(score)\n",
    "\n",
    "# --- Global Constants ---\n",
    "N_SPLITS = 5\n",
    "RANDOM_STATE = 42\n",
    "DATA_PATH = './'\n",
    "N_OPTUNA_TRIALS = 75 # A strong number for a comprehensive search\n",
    "COMPETITION_ALPHA = 0.1\n",
    "\n",
    "# --- Load Raw Data ---\n",
    "try:\n",
    "    # We drop the low-variance columns they identified right away\n",
    "    drop_cols=['id', 'golf', 'view_rainier', 'view_skyline', 'view_lakesamm', 'view_otherwater', 'view_other']\n",
    "    df_train = pd.read_csv(DATA_PATH + 'dataset.csv').drop(columns=drop_cols)\n",
    "    df_test = pd.read_csv(DATA_PATH + 'test.csv').drop(columns=drop_cols)\n",
    "    print(\"Raw data loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"ERROR: Could not find 'dataset.csv' or 'test.csv'.\")\n",
    "    exit()\n",
    "\n",
    "# --- Prepare Target Variable ---\n",
    "y_true = df_train['sale_price'].copy()\n",
    "# The mean-error model works best when predicting the raw price directly\n",
    "# So, we will NOT log-transform the target this time.\n",
    "# df_train.drop('sale_price', axis=1, inplace=True) # We keep sale_price for FE\n",
    "\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bddfc431-ff04-4dc2-bf67-dd8271d45837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Block 2: Synthesized Feature Engineering ---\n",
      "Creating brute-force numerical interaction features...\n",
      "Creating TF-IDF features for text columns...\n",
      "Finalizing feature set...\n",
      "\n",
      "Synthesized FE complete. Total features: 111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# BLOCK 2: SYNTHESIZED FEATURE ENGINEERING (CORRECTED)\n",
    "# =============================================================================\n",
    "print(\"--- Starting Block 2: Synthesized Feature Engineering ---\")\n",
    "\n",
    "def create_synthesized_features(df_train, df_test):\n",
    "    # Combine for consistent processing and reset the index\n",
    "    df_train['is_train'] = 1\n",
    "    df_test['is_train'] = 0\n",
    "    # Store the original id for later, as reset_index will remove it\n",
    "    train_ids = df_train.index\n",
    "    test_ids = df_test.index\n",
    "    all_data = pd.concat([df_train, df_test], axis=0).reset_index(drop=True)\n",
    "\n",
    "    # --- A) Brute-Force Numerical Interactions ---\n",
    "    print(\"Creating brute-force numerical interaction features...\")\n",
    "    NUMS = ['area', 'land_val', 'imp_val', 'sqft_lot', 'sqft', 'sqft_1', 'grade', 'year_built']\n",
    "    for i in range(len(NUMS)):\n",
    "        for j in range(i + 1, len(NUMS)):\n",
    "            all_data[f'{NUMS[i]}_x_{NUMS[j]}'] = all_data[NUMS[i]] * all_data[NUMS[j]]\n",
    "\n",
    "    # --- B) Date Features ---\n",
    "    all_data['sale_date'] = pd.to_datetime(all_data['sale_date'])\n",
    "    all_data['year'] = all_data['sale_date'].dt.year\n",
    "    all_data['month'] = all_data['sale_date'].dt.month\n",
    "    all_data['year_diff'] = all_data['year'] - all_data['year_built']\n",
    "\n",
    "    # --- C) TF-IDF Text Features ---\n",
    "    print(\"Creating TF-IDF features for text columns...\")\n",
    "    text_cols = ['subdivision', 'zoning', 'city', 'sale_warning', 'join_status', 'submarket']\n",
    "    all_data[text_cols] = all_data[text_cols].fillna('missing').astype(str)\n",
    "\n",
    "    for col in text_cols:\n",
    "        tfidf = TfidfVectorizer(analyzer='char', ngram_range=(3, 5), max_features=128, binary=True)\n",
    "        tfidf_matrix = tfidf.fit_transform(all_data[col])\n",
    "        svd = TruncatedSVD(n_components=8, random_state=RANDOM_STATE)\n",
    "        tfidf_svd = svd.fit_transform(tfidf_matrix)\n",
    "        tfidf_df = pd.DataFrame(tfidf_svd, columns=[f'{col}_tfidf_svd_{i}' for i in range(8)])\n",
    "        # This concat will now work because both have a simple 0-based index\n",
    "        all_data = pd.concat([all_data, tfidf_df], axis=1)\n",
    "\n",
    "    # --- D) Log transform some of the new interaction features ---\n",
    "    for c in ['land_val_x_imp_val', 'land_val_x_sqft', 'imp_val_x_sqft']:\n",
    "        if c in all_data.columns:\n",
    "            # Add a small constant to avoid log(0)\n",
    "            all_data[c] = np.log1p(all_data[c].fillna(0))\n",
    "            \n",
    "    # --- E) Final Cleanup ---\n",
    "    print(\"Finalizing feature set...\")\n",
    "    cols_to_drop = ['sale_date', 'subdivision', 'zoning', 'city', 'sale_warning', 'join_status', 'submarket']\n",
    "    all_data = all_data.drop(columns=cols_to_drop)\n",
    "    all_data.fillna(0, inplace=True)\n",
    "\n",
    "    # Separate final datasets\n",
    "    X = all_data[all_data['is_train'] == 1].drop(columns=['is_train', 'sale_price'])\n",
    "    X_test = all_data[all_data['is_train'] == 0].drop(columns=['is_train', 'sale_price'])\n",
    "    \n",
    "    # Restore the original 'id' as the index\n",
    "    X.index = train_ids\n",
    "    X_test.index = test_ids\n",
    "    \n",
    "    X_test = X_test[X.columns]\n",
    "    \n",
    "    return X, X_test\n",
    "\n",
    "# We need to re-run this from the original dataframes\n",
    "X, X_test = create_synthesized_features(df_train, df_test)\n",
    "\n",
    "print(f\"\\nSynthesized FE complete. Total features: {X.shape[1]}\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43d57205-46ad-4d8a-a11b-8c6933567a36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-07 21:59:14,587] A new study created in memory with name: no-name-d179176e-eae6-48c9-a004-08e07050616e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Block 3: Two-Stage Modeling Pipeline ---\n",
      "\n",
      "# STAGE 1, PART 1: Tuning Mean Prediction Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-07 21:59:47,463] Trial 0 finished with value: 99462.39876455825 and parameters: {'eta': 0.044339052061128925, 'max_depth': 9, 'subsample': 0.7988622889107874, 'colsample_bytree': 0.8149248441047022, 'lambda': 3.570682948161265, 'alpha': 0.000517541769069805, 'min_child_weight': 1}. Best is trial 0 with value: 99462.39876455825.\n",
      "[I 2025-07-07 22:00:23,374] Trial 1 finished with value: 99778.40151054737 and parameters: {'eta': 0.0428017757714475, 'max_depth': 9, 'subsample': 0.8158365243298511, 'colsample_bytree': 0.8719250513876937, 'lambda': 2.836221215051975, 'alpha': 0.0003392906968408672, 'min_child_weight': 3}. Best is trial 0 with value: 99462.39876455825.\n",
      "[I 2025-07-07 22:00:55,336] Trial 2 finished with value: 100047.32320257249 and parameters: {'eta': 0.04134957857028555, 'max_depth': 9, 'subsample': 0.7990399952645223, 'colsample_bytree': 0.8598183843257335, 'lambda': 1.3339572253377483, 'alpha': 0.00020821723864121827, 'min_child_weight': 2}. Best is trial 0 with value: 99462.39876455825.\n",
      "[I 2025-07-07 22:01:26,141] Trial 3 finished with value: 99489.53874654359 and parameters: {'eta': 0.03727634838821557, 'max_depth': 9, 'subsample': 0.8022328351358654, 'colsample_bytree': 0.8239803934638922, 'lambda': 1.0363157161157657, 'alpha': 0.0004206212977931566, 'min_child_weight': 3}. Best is trial 0 with value: 99462.39876455825.\n",
      "[I 2025-07-07 22:01:52,580] Trial 4 finished with value: 98887.81328353864 and parameters: {'eta': 0.03727515160417202, 'max_depth': 8, 'subsample': 0.8351232345812843, 'colsample_bytree': 0.8489952664252783, 'lambda': 4.967447634534526, 'alpha': 4.4157944566073806e-05, 'min_child_weight': 3}. Best is trial 4 with value: 98887.81328353864.\n",
      "[I 2025-07-07 22:02:15,513] Trial 5 finished with value: 99178.29956195055 and parameters: {'eta': 0.04052794397651893, 'max_depth': 8, 'subsample': 0.8363394958480429, 'colsample_bytree': 0.8579788375683354, 'lambda': 1.3315370786233964, 'alpha': 0.00023587457910084013, 'min_child_weight': 3}. Best is trial 4 with value: 98887.81328353864.\n",
      "[I 2025-07-07 22:02:41,110] Trial 6 finished with value: 99335.46879136375 and parameters: {'eta': 0.03869894672334251, 'max_depth': 8, 'subsample': 0.787095636252233, 'colsample_bytree': 0.8409808001438321, 'lambda': 1.167955848387285, 'alpha': 2.5323077612913185e-05, 'min_child_weight': 2}. Best is trial 4 with value: 98887.81328353864.\n",
      "[I 2025-07-07 22:03:14,582] Trial 7 finished with value: 99183.65284662589 and parameters: {'eta': 0.04083700377394164, 'max_depth': 9, 'subsample': 0.8074481715041641, 'colsample_bytree': 0.7923891630011511, 'lambda': 2.3321889216232643, 'alpha': 0.00019688534268698472, 'min_child_weight': 2}. Best is trial 4 with value: 98887.81328353864.\n",
      "[I 2025-07-07 22:03:56,796] Trial 8 finished with value: 99863.83305281246 and parameters: {'eta': 0.04488589100978346, 'max_depth': 9, 'subsample': 0.7808206077014196, 'colsample_bytree': 0.8362914067152725, 'lambda': 3.1455295760102833, 'alpha': 9.07388253518425e-05, 'min_child_weight': 3}. Best is trial 4 with value: 98887.81328353864.\n",
      "[I 2025-07-07 22:04:38,157] Trial 9 finished with value: 99408.09142117154 and parameters: {'eta': 0.03989594270321098, 'max_depth': 8, 'subsample': 0.8117455425907639, 'colsample_bytree': 0.8514425524282664, 'lambda': 1.009431815948504, 'alpha': 0.0002568269183513197, 'min_child_weight': 2}. Best is trial 4 with value: 98887.81328353864.\n",
      "[I 2025-07-07 22:05:03,387] Trial 10 finished with value: 99140.75650306487 and parameters: {'eta': 0.037085518376397064, 'max_depth': 8, 'subsample': 0.8381312041119039, 'colsample_bytree': 0.8748098163433431, 'lambda': 4.89811682050504, 'alpha': 1.141168514626369e-05, 'min_child_weight': 1}. Best is trial 4 with value: 98887.81328353864.\n",
      "[I 2025-07-07 22:05:27,102] Trial 11 finished with value: 99303.79086419611 and parameters: {'eta': 0.03707585955658201, 'max_depth': 8, 'subsample': 0.8371949980448515, 'colsample_bytree': 0.8768673591179669, 'lambda': 4.898994660367666, 'alpha': 1.1659268598918687e-05, 'min_child_weight': 1}. Best is trial 4 with value: 98887.81328353864.\n",
      "[I 2025-07-07 22:05:50,988] Trial 12 finished with value: 99079.46225126578 and parameters: {'eta': 0.03872364629236014, 'max_depth': 8, 'subsample': 0.82580826470027, 'colsample_bytree': 0.8796135757777076, 'lambda': 4.897678474910916, 'alpha': 4.0838179014546673e-05, 'min_child_weight': 1}. Best is trial 4 with value: 98887.81328353864.\n",
      "[I 2025-07-07 22:06:14,507] Trial 13 finished with value: 99026.56322421777 and parameters: {'eta': 0.038741650533310606, 'max_depth': 8, 'subsample': 0.8250961503805401, 'colsample_bytree': 0.8168089177208113, 'lambda': 3.93979553442599, 'alpha': 5.185802759982325e-05, 'min_child_weight': 1}. Best is trial 4 with value: 98887.81328353864.\n",
      "[I 2025-07-07 22:06:37,912] Trial 14 finished with value: 98890.70751086777 and parameters: {'eta': 0.038768473276349726, 'max_depth': 8, 'subsample': 0.8275461148424759, 'colsample_bytree': 0.8154171469689733, 'lambda': 3.6645286396553156, 'alpha': 6.890656127020842e-05, 'min_child_weight': 2}. Best is trial 4 with value: 98887.81328353864.\n",
      "[I 2025-07-07 22:07:01,313] Trial 15 finished with value: 99170.2510231773 and parameters: {'eta': 0.03817744890005234, 'max_depth': 8, 'subsample': 0.8261533654568353, 'colsample_bytree': 0.7991551643837692, 'lambda': 2.0759250114965715, 'alpha': 9.912478360793986e-05, 'min_child_weight': 2}. Best is trial 4 with value: 98887.81328353864.\n",
      "[I 2025-07-07 22:07:23,947] Trial 16 finished with value: 99226.65964346477 and parameters: {'eta': 0.03950409091749895, 'max_depth': 8, 'subsample': 0.8208249823413069, 'colsample_bytree': 0.827755741681252, 'lambda': 3.9762546533880543, 'alpha': 2.6083108380261618e-05, 'min_child_weight': 3}. Best is trial 4 with value: 98887.81328353864.\n",
      "[I 2025-07-07 22:07:46,219] Trial 17 finished with value: 99230.51917630987 and parameters: {'eta': 0.042221011373502426, 'max_depth': 8, 'subsample': 0.8318102217379553, 'colsample_bytree': 0.8035673293055092, 'lambda': 2.0252606153719275, 'alpha': 5.6572145458924514e-05, 'min_child_weight': 2}. Best is trial 4 with value: 98887.81328353864.\n",
      "[I 2025-07-07 22:08:08,798] Trial 18 finished with value: 99180.34385905304 and parameters: {'eta': 0.037935229808660216, 'max_depth': 8, 'subsample': 0.831061455953089, 'colsample_bytree': 0.8460032543976622, 'lambda': 2.725526494693047, 'alpha': 2.617831808477176e-05, 'min_child_weight': 3}. Best is trial 4 with value: 98887.81328353864.\n",
      "[I 2025-07-07 22:08:33,833] Trial 19 finished with value: 98782.56429147808 and parameters: {'eta': 0.03955536382306439, 'max_depth': 8, 'subsample': 0.8168817784205179, 'colsample_bytree': 0.8286089782363146, 'lambda': 3.8889487054447804, 'alpha': 0.00013119905300765724, 'min_child_weight': 2}. Best is trial 19 with value: 98782.56429147808.\n",
      "[I 2025-07-07 22:08:55,821] Trial 20 finished with value: 99186.50746951422 and parameters: {'eta': 0.04003038261043742, 'max_depth': 8, 'subsample': 0.8161592616902923, 'colsample_bytree': 0.8306763821854404, 'lambda': 4.193963455295236, 'alpha': 0.0009350203853210051, 'min_child_weight': 3}. Best is trial 19 with value: 98782.56429147808.\n",
      "[I 2025-07-07 22:09:25,780] Trial 21 finished with value: 99048.52435044148 and parameters: {'eta': 0.03928354407046448, 'max_depth': 8, 'subsample': 0.8315729444825368, 'colsample_bytree': 0.8160042679307067, 'lambda': 3.392119822248956, 'alpha': 0.00013843059230775565, 'min_child_weight': 2}. Best is trial 19 with value: 98782.56429147808.\n",
      "[I 2025-07-07 22:09:52,511] Trial 22 finished with value: 98933.02397076519 and parameters: {'eta': 0.038091509123362274, 'max_depth': 8, 'subsample': 0.8211130426891801, 'colsample_bytree': 0.8070262775106487, 'lambda': 4.182070448739981, 'alpha': 7.304034117441305e-05, 'min_child_weight': 2}. Best is trial 19 with value: 98782.56429147808.\n",
      "[I 2025-07-07 22:10:16,165] Trial 23 finished with value: 99190.59052148041 and parameters: {'eta': 0.037802042021873865, 'max_depth': 8, 'subsample': 0.8298837599702925, 'colsample_bytree': 0.8224058667375341, 'lambda': 3.0191684919263806, 'alpha': 0.00015479903482066768, 'min_child_weight': 2}. Best is trial 19 with value: 98782.56429147808.\n",
      "[I 2025-07-07 22:10:38,516] Trial 24 finished with value: 99032.29178404386 and parameters: {'eta': 0.03922882552084993, 'max_depth': 8, 'subsample': 0.8196041618348682, 'colsample_bytree': 0.8404152877151401, 'lambda': 2.4785225038899106, 'alpha': 4.0032544669181474e-05, 'min_child_weight': 2}. Best is trial 19 with value: 98782.56429147808.\n",
      "[I 2025-07-07 22:11:08,459] Trial 25 finished with value: 99030.67355117807 and parameters: {'eta': 0.04145018938793749, 'max_depth': 8, 'subsample': 0.8130219173668787, 'colsample_bytree': 0.8658123037746367, 'lambda': 4.377042634551868, 'alpha': 0.00012786950622477794, 'min_child_weight': 2}. Best is trial 19 with value: 98782.56429147808.\n",
      "[I 2025-07-07 22:11:30,850] Trial 26 finished with value: 99286.27989808058 and parameters: {'eta': 0.040199669231600496, 'max_depth': 8, 'subsample': 0.807893670543536, 'colsample_bytree': 0.8503983364511397, 'lambda': 1.7175257438187215, 'alpha': 6.40976256537254e-05, 'min_child_weight': 3}. Best is trial 19 with value: 98782.56429147808.\n",
      "[I 2025-07-07 22:11:53,653] Trial 27 finished with value: 98925.54032200178 and parameters: {'eta': 0.03857631084799134, 'max_depth': 8, 'subsample': 0.8263850559581968, 'colsample_bytree': 0.8098273372640798, 'lambda': 3.6707976811332648, 'alpha': 3.434759974103634e-05, 'min_child_weight': 2}. Best is trial 19 with value: 98782.56429147808.\n",
      "[I 2025-07-07 22:12:15,244] Trial 28 finished with value: 99349.55951588311 and parameters: {'eta': 0.03745143640019359, 'max_depth': 8, 'subsample': 0.8395323505099195, 'colsample_bytree': 0.833533261145429, 'lambda': 3.263953409431589, 'alpha': 1.8946731078242457e-05, 'min_child_weight': 2}. Best is trial 19 with value: 98782.56429147808.\n",
      "[I 2025-07-07 22:12:47,625] Trial 29 finished with value: 99817.57183983189 and parameters: {'eta': 0.043661044106139676, 'max_depth': 9, 'subsample': 0.8329055349736679, 'colsample_bytree': 0.8232678634693943, 'lambda': 3.5310266434594286, 'alpha': 8.653572562709418e-05, 'min_child_weight': 1}. Best is trial 19 with value: 98782.56429147808.\n",
      "[I 2025-07-07 22:13:10,349] Trial 30 finished with value: 99172.79110723868 and parameters: {'eta': 0.039354719126341066, 'max_depth': 8, 'subsample': 0.8224854007142048, 'colsample_bytree': 0.8435710936791249, 'lambda': 4.405847780780157, 'alpha': 0.0001262684012397739, 'min_child_weight': 3}. Best is trial 19 with value: 98782.56429147808.\n",
      "[I 2025-07-07 22:13:33,818] Trial 31 finished with value: 98836.0912217799 and parameters: {'eta': 0.03859446996259953, 'max_depth': 8, 'subsample': 0.8253214492532635, 'colsample_bytree': 0.8110619430663155, 'lambda': 3.707767654177325, 'alpha': 3.905774835567136e-05, 'min_child_weight': 2}. Best is trial 19 with value: 98782.56429147808.\n",
      "[I 2025-07-07 22:13:55,964] Trial 32 finished with value: 99336.25738872992 and parameters: {'eta': 0.03767955572671503, 'max_depth': 8, 'subsample': 0.8165471918897873, 'colsample_bytree': 0.8107229156732487, 'lambda': 3.696136976693718, 'alpha': 1.82754602114662e-05, 'min_child_weight': 2}. Best is trial 19 with value: 98782.56429147808.\n",
      "[I 2025-07-07 22:14:19,458] Trial 33 finished with value: 99101.86113287682 and parameters: {'eta': 0.03844988888058801, 'max_depth': 8, 'subsample': 0.8285320136697707, 'colsample_bytree': 0.8195960120408392, 'lambda': 2.676000096698496, 'alpha': 4.8436852806842276e-05, 'min_child_weight': 2}. Best is trial 19 with value: 98782.56429147808.\n",
      "[I 2025-07-07 22:14:49,393] Trial 34 finished with value: 99245.97644237272 and parameters: {'eta': 0.03908252235780963, 'max_depth': 9, 'subsample': 0.8352055850404695, 'colsample_bytree': 0.8008825992262997, 'lambda': 4.530829328581798, 'alpha': 7.850004525074114e-05, 'min_child_weight': 2}. Best is trial 19 with value: 98782.56429147808.\n",
      "[I 2025-07-07 22:15:12,592] Trial 35 finished with value: 99066.11868847997 and parameters: {'eta': 0.039817186758935655, 'max_depth': 8, 'subsample': 0.8230550707394001, 'colsample_bytree': 0.8267698217260611, 'lambda': 3.754620817999738, 'alpha': 0.0003164267517305162, 'min_child_weight': 2}. Best is trial 19 with value: 98782.56429147808.\n",
      "[I 2025-07-07 22:15:34,254] Trial 36 finished with value: 99131.39304983059 and parameters: {'eta': 0.04060343035027825, 'max_depth': 8, 'subsample': 0.8031271696032737, 'colsample_bytree': 0.7950258895320923, 'lambda': 3.173433147788989, 'alpha': 0.0006156186694798534, 'min_child_weight': 3}. Best is trial 19 with value: 98782.56429147808.\n",
      "[I 2025-07-07 22:16:05,358] Trial 37 finished with value: 99595.72681596334 and parameters: {'eta': 0.04133406710403882, 'max_depth': 9, 'subsample': 0.7927540068603591, 'colsample_bytree': 0.8585259478285933, 'lambda': 2.949208604446733, 'alpha': 0.00018715294577704997, 'min_child_weight': 1}. Best is trial 19 with value: 98782.56429147808.\n",
      "[I 2025-07-07 22:16:28,762] Trial 38 finished with value: 99232.92356874305 and parameters: {'eta': 0.038299284173421114, 'max_depth': 8, 'subsample': 0.8180690573935021, 'colsample_bytree': 0.8127420526693193, 'lambda': 1.7920494535299727, 'alpha': 3.256179062576403e-05, 'min_child_weight': 2}. Best is trial 19 with value: 98782.56429147808.\n",
      "[I 2025-07-07 22:16:53,060] Trial 39 finished with value: 98832.10749548954 and parameters: {'eta': 0.03752991472271749, 'max_depth': 8, 'subsample': 0.835476161669284, 'colsample_bytree': 0.8342170032472264, 'lambda': 4.5063905750601085, 'alpha': 1.6488504774566382e-05, 'min_child_weight': 3}. Best is trial 19 with value: 98782.56429147808.\n",
      "[I 2025-07-07 22:17:22,407] Trial 40 finished with value: 99032.41069468117 and parameters: {'eta': 0.03748497002548896, 'max_depth': 9, 'subsample': 0.8345284072382422, 'colsample_bytree': 0.8368023114669786, 'lambda': 4.670915755021232, 'alpha': 1.5558866805878684e-05, 'min_child_weight': 3}. Best is trial 19 with value: 98782.56429147808.\n",
      "[I 2025-07-07 22:17:44,744] Trial 41 finished with value: 99010.15640832005 and parameters: {'eta': 0.037843472133898916, 'max_depth': 8, 'subsample': 0.8289506796210752, 'colsample_bytree': 0.8511643861726084, 'lambda': 4.023049176421985, 'alpha': 2.1543678973357217e-05, 'min_child_weight': 3}. Best is trial 19 with value: 98782.56429147808.\n",
      "[I 2025-07-07 22:18:07,932] Trial 42 finished with value: 98987.56091550089 and parameters: {'eta': 0.03724537849688668, 'max_depth': 8, 'subsample': 0.8348602494726443, 'colsample_bytree': 0.8308941571151134, 'lambda': 3.400630762124841, 'alpha': 1.4777776055514662e-05, 'min_child_weight': 3}. Best is trial 19 with value: 98782.56429147808.\n",
      "[I 2025-07-07 22:18:31,195] Trial 43 finished with value: 99012.35930933067 and parameters: {'eta': 0.03881518787485996, 'max_depth': 8, 'subsample': 0.8124588667603827, 'colsample_bytree': 0.8181318752658037, 'lambda': 4.57858935511878, 'alpha': 6.223514121716793e-05, 'min_child_weight': 3}. Best is trial 19 with value: 98782.56429147808.\n",
      "[I 2025-07-07 22:18:53,714] Trial 44 finished with value: 99004.52482588864 and parameters: {'eta': 0.03824547880676075, 'max_depth': 8, 'subsample': 0.8387908441591857, 'colsample_bytree': 0.8381746219915603, 'lambda': 4.911622849405611, 'alpha': 3.3431382429353795e-05, 'min_child_weight': 2}. Best is trial 19 with value: 98782.56429147808.\n",
      "[I 2025-07-07 22:19:16,698] Trial 45 finished with value: 98926.98430660868 and parameters: {'eta': 0.038918555850943365, 'max_depth': 8, 'subsample': 0.8238561202792811, 'colsample_bytree': 0.8255143591572501, 'lambda': 3.8733003696749035, 'alpha': 4.534710484281379e-05, 'min_child_weight': 2}. Best is trial 19 with value: 98782.56429147808.\n",
      "[I 2025-07-07 22:19:39,722] Trial 46 finished with value: 98997.00520722836 and parameters: {'eta': 0.03752721767800539, 'max_depth': 8, 'subsample': 0.8276131192556277, 'colsample_bytree': 0.8549211715827657, 'lambda': 4.379017067859427, 'alpha': 0.00011470220457847031, 'min_child_weight': 3}. Best is trial 19 with value: 98782.56429147808.\n",
      "[I 2025-07-07 22:20:01,671] Trial 47 finished with value: 98861.69409837159 and parameters: {'eta': 0.037017206920354026, 'max_depth': 8, 'subsample': 0.8366876586712532, 'colsample_bytree': 0.8455896794746383, 'lambda': 4.096528606278596, 'alpha': 9.898475553547559e-05, 'min_child_weight': 3}. Best is trial 19 with value: 98782.56429147808.\n",
      "[I 2025-07-07 22:20:24,521] Trial 48 finished with value: 98736.35650559525 and parameters: {'eta': 0.037120369691842514, 'max_depth': 8, 'subsample': 0.8373515451379423, 'colsample_bytree': 0.8458637120195022, 'lambda': 4.197529031704034, 'alpha': 0.00025392391565756103, 'min_child_weight': 3}. Best is trial 48 with value: 98736.35650559525.\n",
      "[I 2025-07-07 22:20:48,824] Trial 49 finished with value: 99139.10905389457 and parameters: {'eta': 0.03742417133619254, 'max_depth': 8, 'subsample': 0.8399574354383547, 'colsample_bytree': 0.8670030311203906, 'lambda': 4.149140586596523, 'alpha': 0.0002779513773581518, 'min_child_weight': 3}. Best is trial 48 with value: 98736.35650559525.\n",
      "[I 2025-07-07 22:21:11,887] Trial 50 finished with value: 98718.03434023593 and parameters: {'eta': 0.03701101058998866, 'max_depth': 8, 'subsample': 0.8368011847822819, 'colsample_bytree': 0.8552465879240381, 'lambda': 3.5004386003189567, 'alpha': 0.0004666158466146097, 'min_child_weight': 3}. Best is trial 50 with value: 98718.03434023593.\n",
      "[I 2025-07-07 22:21:33,603] Trial 51 finished with value: 98746.38998971051 and parameters: {'eta': 0.03731848964368521, 'max_depth': 8, 'subsample': 0.8365415754528017, 'colsample_bytree': 0.8469890131430567, 'lambda': 3.435052851208195, 'alpha': 0.0004475718277236432, 'min_child_weight': 3}. Best is trial 50 with value: 98718.03434023593.\n",
      "[I 2025-07-07 22:21:56,935] Trial 52 finished with value: 99103.48853597435 and parameters: {'eta': 0.03705956171629361, 'max_depth': 8, 'subsample': 0.8326490867795324, 'colsample_bytree': 0.865947634301238, 'lambda': 3.524286550793785, 'alpha': 0.0004699638611885032, 'min_child_weight': 3}. Best is trial 50 with value: 98718.03434023593.\n",
      "[I 2025-07-07 22:22:24,012] Trial 53 finished with value: 98787.30153213014 and parameters: {'eta': 0.03790628940233715, 'max_depth': 8, 'subsample': 0.8373064234491914, 'colsample_bytree': 0.8622475210923655, 'lambda': 3.327036681425703, 'alpha': 0.0003835900301899572, 'min_child_weight': 3}. Best is trial 50 with value: 98718.03434023593.\n",
      "[I 2025-07-07 22:22:48,915] Trial 54 finished with value: 98911.68424407706 and parameters: {'eta': 0.037872448163225235, 'max_depth': 8, 'subsample': 0.8374824538214704, 'colsample_bytree': 0.8623526236761955, 'lambda': 2.9399483814326017, 'alpha': 0.00038508980087634384, 'min_child_weight': 3}. Best is trial 50 with value: 98718.03434023593.\n",
      "[I 2025-07-07 22:23:11,497] Trial 55 finished with value: 99029.87218006494 and parameters: {'eta': 0.03768659408064079, 'max_depth': 8, 'subsample': 0.8336885455932005, 'colsample_bytree': 0.854781861775086, 'lambda': 3.1324809085532586, 'alpha': 0.0005941651726566256, 'min_child_weight': 3}. Best is trial 50 with value: 98718.03434023593.\n",
      "[I 2025-07-07 22:23:38,103] Trial 56 finished with value: 98792.49461371041 and parameters: {'eta': 0.03724999135454918, 'max_depth': 8, 'subsample': 0.8362888218061643, 'colsample_bytree': 0.8710008365001803, 'lambda': 2.729270115035066, 'alpha': 0.0008224859619871368, 'min_child_weight': 3}. Best is trial 50 with value: 98718.03434023593.\n",
      "[I 2025-07-07 22:24:29,677] Trial 57 finished with value: 99039.43133923983 and parameters: {'eta': 0.03718717412629492, 'max_depth': 8, 'subsample': 0.7973324987703233, 'colsample_bytree': 0.8699253745452155, 'lambda': 2.5498604975440613, 'alpha': 0.0008030668783821422, 'min_child_weight': 3}. Best is trial 50 with value: 98718.03434023593.\n",
      "[I 2025-07-07 22:24:52,400] Trial 58 finished with value: 99117.67422614395 and parameters: {'eta': 0.03797453084803479, 'max_depth': 8, 'subsample': 0.8304992210704414, 'colsample_bytree': 0.8734103905775104, 'lambda': 2.718855040201104, 'alpha': 0.0007245159623712182, 'min_child_weight': 3}. Best is trial 50 with value: 98718.03434023593.\n",
      "[I 2025-07-07 22:25:22,283] Trial 59 finished with value: 99118.40773539494 and parameters: {'eta': 0.039668792846169386, 'max_depth': 8, 'subsample': 0.8372863915146799, 'colsample_bytree': 0.8629434516963319, 'lambda': 2.3357732814473597, 'alpha': 0.00036698281717213185, 'min_child_weight': 3}. Best is trial 50 with value: 98718.03434023593.\n",
      "[I 2025-07-07 22:26:44,711] Trial 60 finished with value: 99224.19833891328 and parameters: {'eta': 0.04236174793438138, 'max_depth': 8, 'subsample': 0.8378062322995603, 'colsample_bytree': 0.8553273170589136, 'lambda': 3.1752665918396104, 'alpha': 0.0004636121542987554, 'min_child_weight': 3}. Best is trial 50 with value: 98718.03434023593.\n",
      "[I 2025-07-07 22:27:20,315] Trial 61 finished with value: 98847.59598493026 and parameters: {'eta': 0.03734098257616073, 'max_depth': 8, 'subsample': 0.8348329073291492, 'colsample_bytree': 0.8412738669815967, 'lambda': 3.508812480221102, 'alpha': 0.00023156854099013241, 'min_child_weight': 3}. Best is trial 50 with value: 98718.03434023593.\n",
      "[I 2025-07-07 22:27:54,252] Trial 62 finished with value: 99058.46419160758 and parameters: {'eta': 0.03809748133380476, 'max_depth': 8, 'subsample': 0.8399653854291969, 'colsample_bytree': 0.877433575648836, 'lambda': 3.877167817174926, 'alpha': 0.0009997330127887079, 'min_child_weight': 3}. Best is trial 50 with value: 98718.03434023593.\n",
      "[I 2025-07-07 22:28:43,294] Trial 63 finished with value: 99157.62707931246 and parameters: {'eta': 0.037016652867496155, 'max_depth': 8, 'subsample': 0.8358745012640872, 'colsample_bytree': 0.8704998189219378, 'lambda': 1.1182592990496851, 'alpha': 0.0002976383778490216, 'min_child_weight': 3}. Best is trial 50 with value: 98718.03434023593.\n",
      "[I 2025-07-07 22:30:06,520] Trial 64 finished with value: 98906.36800530086 and parameters: {'eta': 0.03760676559551503, 'max_depth': 8, 'subsample': 0.8322503177620056, 'colsample_bytree': 0.8489135975366725, 'lambda': 3.3736602328968637, 'alpha': 0.000574826017204009, 'min_child_weight': 3}. Best is trial 50 with value: 98718.03434023593.\n",
      "[I 2025-07-07 22:31:15,410] Trial 65 finished with value: 99084.23180304725 and parameters: {'eta': 0.03733747850375646, 'max_depth': 8, 'subsample': 0.8309915239523447, 'colsample_bytree': 0.8336806456238596, 'lambda': 2.8138017284036296, 'alpha': 0.00017977632729098046, 'min_child_weight': 3}. Best is trial 50 with value: 98718.03434023593.\n",
      "[I 2025-07-07 22:31:52,305] Trial 66 finished with value: 98937.11230877925 and parameters: {'eta': 0.037686380620810665, 'max_depth': 8, 'subsample': 0.8366373015641106, 'colsample_bytree': 0.8463758966227873, 'lambda': 3.272325151561447, 'alpha': 0.0004339246933943576, 'min_child_weight': 3}. Best is trial 50 with value: 98718.03434023593.\n",
      "[I 2025-07-07 22:32:27,851] Trial 67 finished with value: 98953.80546497442 and parameters: {'eta': 0.03790783186838362, 'max_depth': 8, 'subsample': 0.7884529661703454, 'colsample_bytree': 0.8592984520160422, 'lambda': 4.260873448319923, 'alpha': 0.0007203886159393428, 'min_child_weight': 3}. Best is trial 50 with value: 98718.03434023593.\n",
      "[I 2025-07-07 22:32:52,850] Trial 68 finished with value: 99232.79457921156 and parameters: {'eta': 0.03837266444807305, 'max_depth': 8, 'subsample': 0.7816936653847191, 'colsample_bytree': 0.8301499586616125, 'lambda': 4.689497739931834, 'alpha': 0.0002330445901032413, 'min_child_weight': 3}. Best is trial 50 with value: 98718.03434023593.\n",
      "[I 2025-07-07 22:33:18,166] Trial 69 finished with value: 99292.80819878145 and parameters: {'eta': 0.03812998559080749, 'max_depth': 8, 'subsample': 0.8331837662738234, 'colsample_bytree': 0.8536046674776098, 'lambda': 3.066180884125522, 'alpha': 0.000541075211344092, 'min_child_weight': 3}. Best is trial 50 with value: 98718.03434023593.\n",
      "[I 2025-07-07 22:33:48,648] Trial 70 finished with value: 99065.70522637993 and parameters: {'eta': 0.03723171661724553, 'max_depth': 8, 'subsample': 0.8032435388352345, 'colsample_bytree': 0.8616457284306259, 'lambda': 3.9059572481353304, 'alpha': 0.0003418415487248181, 'min_child_weight': 3}. Best is trial 50 with value: 98718.03434023593.\n",
      "[I 2025-07-07 22:34:12,617] Trial 71 finished with value: 99061.23972573734 and parameters: {'eta': 0.038634635229228165, 'max_depth': 8, 'subsample': 0.8296199054928366, 'colsample_bytree': 0.8391276574606344, 'lambda': 3.7092393545765425, 'alpha': 1.0762362438282628e-05, 'min_child_weight': 2}. Best is trial 50 with value: 98718.03434023593.\n",
      "[I 2025-07-07 22:34:37,709] Trial 72 finished with value: 99073.03875424433 and parameters: {'eta': 0.03851195359965246, 'max_depth': 8, 'subsample': 0.8259082264225783, 'colsample_bytree': 0.8482816843508375, 'lambda': 3.5827911275812547, 'alpha': 0.0003896484540767068, 'min_child_weight': 3}. Best is trial 50 with value: 98718.03434023593.\n",
      "[I 2025-07-07 22:35:04,169] Trial 73 finished with value: 98939.27543700732 and parameters: {'eta': 0.03757160885633542, 'max_depth': 8, 'subsample': 0.8383034316333073, 'colsample_bytree': 0.8429358992170422, 'lambda': 3.3264710320241964, 'alpha': 0.0008429230990516344, 'min_child_weight': 2}. Best is trial 50 with value: 98718.03434023593.\n",
      "[I 2025-07-07 22:35:30,602] Trial 74 finished with value: 98630.61366533213 and parameters: {'eta': 0.04020573204882525, 'max_depth': 8, 'subsample': 0.8354635892803999, 'colsample_bytree': 0.8682974768757563, 'lambda': 3.7980915923643424, 'alpha': 0.0002713444216874736, 'min_child_weight': 3}. Best is trial 74 with value: 98630.61366533213.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Mean Model Tuning Complete. Best Validation RMSE: $98,630.61\n",
      "\n",
      "# STAGE 1, PART 2: K-Fold Training of Mean Model...\n",
      "  Mean Model - Fold 1/5...\n",
      "  Mean Model - Fold 2/5...\n",
      "  Mean Model - Fold 3/5...\n",
      "  Mean Model - Fold 4/5...\n",
      "  Mean Model - Fold 5/5...\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# BLOCK 3: TWO-STAGE TUNING, TRAINING, AND SUBMISSION\n",
    "# =============================================================================\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"\\n--- Starting Block 3: Two-Stage Modeling Pipeline ---\")\n",
    "\n",
    "# --- STAGE 1, PART 1: Tuning Mean Prediction Model ---\n",
    "print(\"\\n# STAGE 1, PART 1: Tuning Mean Prediction Model...\")\n",
    "def objective_mean(trial):\n",
    "    train_x, val_x, train_y, val_y = train_test_split(X, y_true, test_size=0.2, random_state=RANDOM_STATE)\n",
    "    params = {\n",
    "            'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'tree_method':'hist',\n",
    "            'eta': trial.suggest_float('eta', 0.037, 0.045),\n",
    "            'max_depth': trial.suggest_int('max_depth', 8, 9),\n",
    "            'subsample': trial.suggest_float('subsample', 0.78, 0.84),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.79, 0.88), # Centered around 0.852\n",
    "            'lambda': trial.suggest_float('lambda', 1.0, 5.0, log=True), \n",
    "            'alpha': trial.suggest_float('alpha', 1e-5, 1e-3, log=True), \n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 3)\n",
    "            }\n",
    "    \n",
    "    model = xgb.XGBRegressor(**params, n_estimators=2000, random_state=RANDOM_STATE, n_jobs=-1, early_stopping_rounds=100)\n",
    "    model.fit(train_x, train_y, eval_set=[(val_x, val_y)], verbose=False)\n",
    "    preds = model.predict(val_x)\n",
    "    return np.sqrt(mean_squared_error(val_y, preds))\n",
    "\n",
    "study_mean = optuna.create_study(direction='minimize')\n",
    "study_mean.optimize(objective_mean, n_trials=N_OPTUNA_TRIALS)\n",
    "best_params_mean = study_mean.best_params\n",
    "print(f\"# Mean Model Tuning Complete. Best Validation RMSE: ${study_mean.best_value:,.2f}\")\n",
    "\n",
    "# --- STAGE 1, PART 2: K-Fold Training of Mean Model ---\n",
    "print(\"\\n# STAGE 1, PART 2: K-Fold Training of Mean Model...\")\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "oof_mean_preds = np.zeros(len(X))\n",
    "test_mean_preds = np.zeros(len(X_test))\n",
    "grade_for_stratify = pd.read_csv(DATA_PATH + 'dataset.csv')['grade']\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, grade_for_stratify)):\n",
    "    print(f\"  Mean Model - Fold {fold+1}/{N_SPLITS}...\")\n",
    "    model = xgb.XGBRegressor(**best_params_mean, n_estimators=2000, objective='reg:squarederror', eval_metric='rmse', tree_method='hist', random_state=RANDOM_STATE, n_jobs=-1, early_stopping_rounds=100)\n",
    "    model.fit(X.iloc[train_idx], y_true.iloc[train_idx], eval_set=[(X.iloc[val_idx], y_true.iloc[val_idx])], verbose=False)\n",
    "    oof_mean_preds[val_idx] = model.predict(X.iloc[val_idx])\n",
    "    test_mean_preds += model.predict(X_test) / N_SPLITS\n",
    "    \n",
    "# --- NEW: CALCULATE AND PRINT FINAL OOF RMSE ---\n",
    "final_mean_rmse = np.sqrt(mean_squared_error(y_true, oof_mean_preds))\n",
    "print(f\"\\n# Mean model K-Fold training complete.\")\n",
    "print(f\"# Final OOF RMSE for Mean Model: ${final_mean_rmse:,.2f}\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b805a9fc-b19e-4a63-92e7-bb4b0eaf803e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-07 22:39:08,307] A new study created in memory with name: no-name-37f638ba-46a9-47a0-9b1c-c472fa258eed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# STAGE 2, PART 1: Tuning Error Prediction Model...\n",
      "# EXPLANATION: We are now finding the best settings for the second model, which predicts the error.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-07 22:39:35,358] Trial 0 finished with value: 63106.175318776724 and parameters: {'eta': 0.015098086178762671, 'max_depth': 8, 'subsample': 0.9402423109857557, 'colsample_bytree': 0.7343936609856876, 'lambda': 0.5779233634321708, 'alpha': 0.5944238761179331}. Best is trial 0 with value: 63106.175318776724.\n",
      "[I 2025-07-07 22:40:02,448] Trial 1 finished with value: 63176.50546114744 and parameters: {'eta': 0.018140915457811133, 'max_depth': 10, 'subsample': 0.9408214665753196, 'colsample_bytree': 0.7446604536112295, 'lambda': 0.6759255106173002, 'alpha': 0.609401889983015}. Best is trial 0 with value: 63106.175318776724.\n",
      "[I 2025-07-07 22:40:19,063] Trial 2 finished with value: 63236.796616364016 and parameters: {'eta': 0.015489706986717276, 'max_depth': 10, 'subsample': 0.9285388172256686, 'colsample_bytree': 0.7320509603083513, 'lambda': 0.5315861250557748, 'alpha': 0.5913328251622253}. Best is trial 0 with value: 63106.175318776724.\n",
      "[I 2025-07-07 22:40:29,617] Trial 3 finished with value: 63167.3656437045 and parameters: {'eta': 0.017981511844248343, 'max_depth': 9, 'subsample': 0.9253718599866384, 'colsample_bytree': 0.7354214897724337, 'lambda': 0.6970380071921567, 'alpha': 0.5659651992554201}. Best is trial 0 with value: 63106.175318776724.\n",
      "[I 2025-07-07 22:40:41,867] Trial 4 finished with value: 63269.84259378717 and parameters: {'eta': 0.016297982115300057, 'max_depth': 9, 'subsample': 0.9450096300812864, 'colsample_bytree': 0.7324089545192519, 'lambda': 0.6261847149548531, 'alpha': 0.5785649316328628}. Best is trial 0 with value: 63106.175318776724.\n",
      "[I 2025-07-07 22:40:52,872] Trial 5 finished with value: 63263.51974131471 and parameters: {'eta': 0.018105510484208272, 'max_depth': 10, 'subsample': 0.9130133061472296, 'colsample_bytree': 0.7396885728042508, 'lambda': 0.5841702944293994, 'alpha': 0.5799236411707696}. Best is trial 0 with value: 63106.175318776724.\n",
      "[I 2025-07-07 22:41:09,207] Trial 6 finished with value: 63181.522375975386 and parameters: {'eta': 0.015247088223452951, 'max_depth': 10, 'subsample': 0.93879452682723, 'colsample_bytree': 0.7407074404013942, 'lambda': 0.6177398745539971, 'alpha': 0.5726582355088171}. Best is trial 0 with value: 63106.175318776724.\n",
      "[I 2025-07-07 22:41:20,326] Trial 7 finished with value: 63299.02109781168 and parameters: {'eta': 0.014203149259310455, 'max_depth': 10, 'subsample': 0.9224737302470891, 'colsample_bytree': 0.7356955920101755, 'lambda': 0.5053537991360403, 'alpha': 0.560029476850849}. Best is trial 0 with value: 63106.175318776724.\n",
      "[I 2025-07-07 22:41:28,839] Trial 8 finished with value: 63276.116371491604 and parameters: {'eta': 0.018867515134815143, 'max_depth': 9, 'subsample': 0.9102600445651705, 'colsample_bytree': 0.7353207346726813, 'lambda': 0.5505375434117681, 'alpha': 0.6172805424908085}. Best is trial 0 with value: 63106.175318776724.\n",
      "[I 2025-07-07 22:41:39,865] Trial 9 finished with value: 63144.81192286016 and parameters: {'eta': 0.01620255356715997, 'max_depth': 9, 'subsample': 0.9382352178931408, 'colsample_bytree': 0.7357035994001199, 'lambda': 0.5038434739299881, 'alpha': 0.6127054103972713}. Best is trial 0 with value: 63106.175318776724.\n",
      "[I 2025-07-07 22:41:50,164] Trial 10 finished with value: 63203.03728353563 and parameters: {'eta': 0.014145079723630686, 'max_depth': 8, 'subsample': 0.9016034252267526, 'colsample_bytree': 0.7251242406753802, 'lambda': 0.5754405004016014, 'alpha': 0.5973632602991814}. Best is trial 0 with value: 63106.175318776724.\n",
      "[I 2025-07-07 22:42:01,820] Trial 11 finished with value: 63117.59954252976 and parameters: {'eta': 0.01664240182646899, 'max_depth': 8, 'subsample': 0.9343764439276218, 'colsample_bytree': 0.7302640916259766, 'lambda': 0.5035646998684107, 'alpha': 0.6261226372433801}. Best is trial 0 with value: 63106.175318776724.\n",
      "[I 2025-07-07 22:42:13,980] Trial 12 finished with value: 63176.96152570745 and parameters: {'eta': 0.017123353348474195, 'max_depth': 8, 'subsample': 0.9325129809977386, 'colsample_bytree': 0.7272102079929815, 'lambda': 0.5431643176341491, 'alpha': 0.6238160232873611}. Best is trial 0 with value: 63106.175318776724.\n",
      "[I 2025-07-07 22:42:24,142] Trial 13 finished with value: 63146.53351793311 and parameters: {'eta': 0.015366506800905256, 'max_depth': 8, 'subsample': 0.9470536044961441, 'colsample_bytree': 0.7298571941215432, 'lambda': 0.6266995427187105, 'alpha': 0.6032525187689719}. Best is trial 0 with value: 63106.175318776724.\n"
     ]
    }
   ],
   "source": [
    "# --- STAGE 2, PART 1: NEW - Tuning the Error Model ---\n",
    "print(\"\\n# STAGE 2, PART 1: Tuning Error Prediction Model...\")\n",
    "print(\"# EXPLANATION: We are now finding the best settings for the second model, which predicts the error.\")\n",
    "error_target = np.abs(y_true - oof_mean_preds)\n",
    "X_for_error = X.copy()\n",
    "X_for_error['mean_pred_oof'] = oof_mean_preds\n",
    "\n",
    "def objective_error(trial):\n",
    "    train_x, val_x, train_y, val_y = train_test_split(X_for_error, error_target, test_size=0.2, random_state=RANDOM_STATE)\n",
    "    # The error model might benefit from different, simpler parameters\n",
    "    params = {\n",
    "            'objective': 'reg:squarederror',\n",
    "            'eval_metric': 'rmse',\n",
    "            'tree_method': 'hist',\n",
    "            'eta': trial.suggest_float('eta', 0.014, 0.019),\n",
    "            'max_depth': trial.suggest_int('max_depth', 8, 10),\n",
    "            'subsample': trial.suggest_float('subsample', 0.9, 0.95),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.725, 0.745),\n",
    "            'lambda': trial.suggest_float('lambda', 0.5, 0.7, log=True),\n",
    "            'alpha': trial.suggest_float('alpha', 0.55, 0.63),\n",
    "        }\n",
    "\n",
    "\n",
    "    \n",
    "    model = xgb.XGBRegressor(**params, n_estimators=2000, random_state=RANDOM_STATE, n_jobs=-1, early_stopping_rounds=100)\n",
    "    model.fit(train_x, train_y, eval_set=[(val_x, val_y)], verbose=False)\n",
    "    preds = model.predict(val_x)\n",
    "    return np.sqrt(mean_squared_error(val_y, preds))\n",
    "\n",
    "study_error = optuna.create_study(direction='minimize')\n",
    "study_error.optimize(objective_error, n_trials=N_OPTUNA_TRIALS)\n",
    "best_params_error = study_error.best_params\n",
    "print(f\"# Error Model Tuning Complete. Best Validation RMSE: ${study_error.best_value:,.2f}\")\n",
    "\n",
    "# --- STAGE 2, PART 2: K-Fold Training of Error Model with Best Params ---\n",
    "print(\"\\n# STAGE 2, PART 2: K-Fold Training of Error Model...\")\n",
    "X_test_for_error = X_test.copy()\n",
    "X_test_for_error['mean_pred_oof'] = test_mean_preds\n",
    "oof_error_preds = np.zeros(len(X))\n",
    "test_error_preds = np.zeros(len(X_test))\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_for_error, grade_for_stratify)):\n",
    "    print(f\"  Error Model - Fold {fold+1}/{N_SPLITS}...\")\n",
    "    # Use the NEW best parameters for the error model\n",
    "    model = xgb.XGBRegressor(**best_params_error, n_estimators=2000, objective='reg:squarederror', eval_metric='rmse', tree_method='hist', random_state=RANDOM_STATE, n_jobs=-1, early_stopping_rounds=100)\n",
    "    model.fit(X_for_error.iloc[train_idx], error_target.iloc[train_idx], eval_set=[(X_for_error.iloc[val_idx], error_target.iloc[val_idx])], verbose=False)\n",
    "    oof_error_preds[val_idx] = model.predict(X_for_error.iloc[val_idx])\n",
    "    test_error_preds += model.predict(X_test_for_error) / N_SPLITS\n",
    "\n",
    "# --- NEW: CALCULATE AND PRINT FINAL OOF RMSE ---\n",
    "final_error_rmse = np.sqrt(mean_squared_error(error_target, oof_error_preds))\n",
    "print(f\"\\n# Error model K-Fold training complete.\")\n",
    "print(f\"# Final OOF RMSE for Error Model: ${final_error_rmse:,.2f}\")\n",
    "print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fcfcff-e8ce-4ddd-a536-c9a957b3bee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FINAL ASYMMETRIC CALIBRATION AND SUBMISSION (ULTIMATE ROBUST VERSION)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n--- Final Asymmetric Calibration ---\")\n",
    "\n",
    "# --- Safely reload y_true to ensure it's available ---\n",
    "y_true = pd.read_csv('./dataset.csv')['sale_price']\n",
    "\n",
    "# --- Your existing correct code ---\n",
    "oof_error_final = np.clip(oof_error_preds, 0, None) \n",
    "best_a, best_b, best_metric = 2.0, 2.0, float('inf')\n",
    "\n",
    "for a in np.arange(1.90, 2.31, 0.01):\n",
    "    for b in np.arange(2.10, 2.51, 0.01):\n",
    "        low = oof_mean_preds - oof_error_final * a\n",
    "        high = oof_mean_preds + oof_error_final * b\n",
    "        # We need the winkler_score function defined here or in a previous cell\n",
    "        metric, coverage = winkler_score(y_true, low, high, alpha=COMPETITION_ALPHA, return_coverage=True)\n",
    "        if metric < best_metric:\n",
    "            best_metric = metric\n",
    "            best_a, best_b = a, b\n",
    "            \n",
    "print(f\"\\nGrid search complete. Final OOF Score: {best_metric:,.2f}. Best multipliers: a={best_a:.2f}, b={best_b:.2f}\")\n",
    "\n",
    "\n",
    "# --- Create Final Submission ---\n",
    "print(\"\\nCreating final submission file...\")\n",
    "test_error_final = np.clip(test_error_preds, 0, None)\n",
    "final_lower = test_mean_preds - test_error_final * best_a\n",
    "final_upper = test_mean_preds + test_error_final * best_b\n",
    "final_upper = np.maximum(final_lower, final_upper)\n",
    "\n",
    "# Your excellent, robust fix for the IDs\n",
    "test_ids = pd.read_csv('./test.csv', usecols=['id'])['id']\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_ids, \n",
    "    'pi_lower': final_lower, \n",
    "    'pi_upper': final_upper\n",
    "})\n",
    "\n",
    "submission_df.to_csv('submission_final_v6.csv', index=False)\n",
    "print(\"\\n'submission_final_v6.csv' created successfully!\")\n",
    "display(submission_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dbcb61-58dd-4089-96af-81258985b476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353b1f4d-300d-4e32-87f2-e28b20397f14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Kaggle Comp)",
   "language": "python",
   "name": "kaggle-comp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
