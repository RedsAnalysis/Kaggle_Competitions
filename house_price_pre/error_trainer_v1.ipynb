{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6de7ef9-ff18-4130-9d6b-0927a934a774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n",
      "Raw data loaded successfully.\n",
      "Setup complete.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# BLOCK 1: SETUP, IMPORTS, AND DATA LOADING\n",
    "# =============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "# --- Library Imports ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "print(\"Libraries imported successfully.\")\n",
    "# --- Helper Function for Winkler Score ---\n",
    "def winkler_score(y_true, lower, upper, alpha=0.1, return_coverage=False):\n",
    "    width = upper - lower\n",
    "    penalty_lower = np.where(y_true < lower, (2 / alpha) * (lower - y_true), 0)\n",
    "    penalty_upper = np.where(y_true > upper, (2 / alpha) * (y_true - upper), 0)\n",
    "    score = width + penalty_lower + penalty_upper\n",
    "    if return_coverage:\n",
    "        coverage = np.mean((y_true >= lower) & (y_true <= upper))\n",
    "        return np.mean(score), coverage\n",
    "    return np.mean(score)\n",
    "# --- Global Constants ---\n",
    "N_SPLITS = 5\n",
    "RANDOM_STATE = 42\n",
    "DATA_PATH = './'\n",
    "N_OPTUNA_TRIALS = 100 # A strong number for a comprehensive search\n",
    "COMPETITION_ALPHA = 0.1\n",
    "\n",
    "# --- Load Raw Data ---\n",
    "try:\n",
    "    # We drop the low-variance columns they identified right away\n",
    "    drop_cols=['id', 'golf', 'view_rainier', 'view_skyline', 'view_lakesamm','view_otherwater', 'view_other']\n",
    "    df_train = pd.read_csv(DATA_PATH + 'dataset.csv').drop(columns=drop_cols)\n",
    "    df_test = pd.read_csv(DATA_PATH + 'test.csv').drop(columns=drop_cols)\n",
    "    print(\"Raw data loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"ERROR: Could not find 'dataset.csv' or 'test.csv'.\")\n",
    "    exit()\n",
    "# --- Prepare Target Variable ---\n",
    "y_true = df_train['sale_price'].copy()\n",
    "# The mean-error model works best when predicting the raw price directly\n",
    "# So, we will NOT log-transform the target this time.\n",
    "# df_train.drop('sale_price', axis=1, inplace=True) # We keep sale_price for FE\n",
    "print(\"Setup complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1276f27-81ea-4223-83bd-12b46f2cc2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Block 2: Synthesized Feature Engineering ---\n",
      "Creating brute-force numerical interaction features...\n",
      "Creating TF-IDF features for text columns...\n",
      "Finalizing feature set...\n",
      "\n",
      "Synthesized FE complete. Total features: 111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# BLOCK 2: SYNTHESIZED FEATURE ENGINEERING (CORRECTED)\n",
    "# =============================================================================\n",
    "print(\"--- Starting Block 2: Synthesized Feature Engineering ---\")\n",
    "def create_synthesized_features(df_train, df_test):\n",
    "    # Combine for consistent processing and reset the index\n",
    "    df_train['is_train'] = 1\n",
    "    df_test['is_train'] = 0\n",
    "    # Store the original id for later, as reset_index will remove it\n",
    "    train_ids = df_train.index\n",
    "    test_ids = df_test.index\n",
    "    all_data = pd.concat([df_train, df_test], axis=0).reset_index(drop=True)\n",
    "    \n",
    "    # --- A) Brute-Force Numerical Interactions ---\n",
    "    print(\"Creating brute-force numerical interaction features...\")\n",
    "    NUMS = ['area', 'land_val', 'imp_val', 'sqft_lot', 'sqft', 'sqft_1','grade', 'year_built']\n",
    "    for i in range(len(NUMS)):\n",
    "        for j in range(i + 1, len(NUMS)):\n",
    "            all_data[f'{NUMS[i]}_x_{NUMS[j]}'] = all_data[NUMS[i]] *all_data[NUMS[j]]\n",
    "    \n",
    "    # --- B) Date Features ---\n",
    "    all_data['sale_date'] = pd.to_datetime(all_data['sale_date'])\n",
    "    all_data['year'] = all_data['sale_date'].dt.year\n",
    "    all_data['month'] = all_data['sale_date'].dt.month\n",
    "    all_data['year_diff'] = all_data['year'] - all_data['year_built']\n",
    "    \n",
    "    # --- C) TF-IDF Text Features ---\n",
    "    print(\"Creating TF-IDF features for text columns...\")\n",
    "    text_cols = ['subdivision', 'zoning', 'city', 'sale_warning','join_status', 'submarket']\n",
    "    all_data[text_cols] = all_data[text_cols].fillna('missing').astype(str)\n",
    "    for col in text_cols:\n",
    "        tfidf = TfidfVectorizer(analyzer='char', ngram_range=(3, 5),max_features=128, binary=True)\n",
    "        tfidf_matrix = tfidf.fit_transform(all_data[col])\n",
    "        svd = TruncatedSVD(n_components=8, random_state=RANDOM_STATE)\n",
    "        tfidf_svd = svd.fit_transform(tfidf_matrix)\n",
    "        tfidf_df = pd.DataFrame(tfidf_svd, columns=[f'{col}_tfidf_svd_{i}' for i in range(8)])\n",
    "        \n",
    "        # This concat will now work because both have a simple 0-based index\n",
    "        all_data = pd.concat([all_data, tfidf_df], axis=1)\n",
    "    \n",
    "    # --- D) Log transform some of the new interaction features ---\n",
    "    for c in ['land_val_x_imp_val', 'land_val_x_sqft', 'imp_val_x_sqft']:\n",
    "        if c in all_data.columns:\n",
    "            # Add a small constant to avoid log(0)\n",
    "            all_data[c] = np.log1p(all_data[c].fillna(0))\n",
    "    \n",
    "    # --- E) Final Cleanup ---\n",
    "    print(\"Finalizing feature set...\")\n",
    "    cols_to_drop = ['sale_date', 'subdivision', 'zoning', 'city','sale_warning', 'join_status', 'submarket']\n",
    "    all_data = all_data.drop(columns=cols_to_drop)\n",
    "    all_data.fillna(0, inplace=True)\n",
    "    \n",
    "    # Separate final datasets\n",
    "    X = all_data[all_data['is_train'] == 1].drop(columns=['is_train','sale_price'])\n",
    "    X_test = all_data[all_data['is_train'] == 0].drop(columns=['is_train','sale_price'])\n",
    "    \n",
    "    # Restore the original 'id' as the index\n",
    "    X.index = train_ids\n",
    "    X_test.index = test_ids\n",
    "    X_test = X_test[X.columns]\n",
    "    return X, X_test\n",
    "\n",
    "# We need to re-run this from the original dataframes\n",
    "X, X_test = create_synthesized_features(df_train, df_test)\n",
    "print(f\"\\nSynthesized FE complete. Total features: {X.shape[1]}\")\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e05125d-2006-4788-8895-83c106c31b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STAGE 1: K-Fold Training of Mean Model ---\n",
      "# Using pre-tuned, optimal hyperparameters.\n",
      " Mean Model - Fold 1/5...\n",
      " Mean Model - Fold 2/5...\n",
      " Mean Model - Fold 3/5...\n",
      " Mean Model - Fold 4/5...\n",
      " Mean Model - Fold 5/5...\n",
      "\n",
      "# Mean model K-Fold training complete.\n",
      "# Final OOF RMSE for Mean Model: $98,884.39\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# BLOCK 3: K-FOLD TRAINING OF MEAN MODEL (NO TUNING)\n",
    "# =============================================================================\n",
    "print(\"\\n--- STAGE 1: K-Fold Training of Mean Model ---\")\n",
    "print(\"# Using pre-tuned, optimal hyperparameters.\")\n",
    "# --- YOUR BEST PARAMETERS FOR THE MEAN MODEL ---\n",
    "# These are the parameters from your most successful Optuna run.\n",
    "best_params_mean = {\n",
    "            'eta': 0.033165561052369404,\n",
    "            'max_depth': 8,\n",
    "            'subsample': 0.8906405742494341,\n",
    "            'colsample_bytree': 0.6676611493633322,\n",
    "            'lambda': 4.978069972474589,\n",
    "            'alpha': 0.004983194427373584,\n",
    "            'min_child_weight': 3\n",
    "            }\n",
    "\n",
    "# --- K-Fold Training ---\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True,random_state=RANDOM_STATE)\n",
    "oof_mean_preds = np.zeros(len(X))\n",
    "test_mean_preds = np.zeros(len(X_test))\n",
    "\n",
    "\n",
    "# THE FIX: Reload the 'grade' column for stratification as the original df was deleted.\n",
    "grade_for_stratify = pd.read_csv(DATA_PATH + 'dataset.csv')['grade']\n",
    "\n",
    "# Add the other required XGBoost parameters\n",
    "final_params_mean = {'objective': 'reg:squarederror', 'eval_metric': 'rmse','tree_method': 'hist', 'random_state': RANDOM_STATE, 'n_jobs': -1,**best_params_mean}\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, grade_for_stratify)):\n",
    "    print(f\" Mean Model - Fold {fold+1}/{N_SPLITS}...\")\n",
    "    model = xgb.XGBRegressor(**final_params_mean, n_estimators=2500,early_stopping_rounds=100)\n",
    "    model.fit(X.iloc[train_idx], y_true.iloc[train_idx], eval_set=[(X.iloc[val_idx], y_true.iloc[val_idx])], verbose=False)\n",
    "    oof_mean_preds[val_idx] = model.predict(X.iloc[val_idx])\n",
    "    test_mean_preds += model.predict(X_test) / N_SPLITS\n",
    "\n",
    "    \n",
    "# --- NEW: CALCULATE AND PRINT FINAL OOF RMSE ---\n",
    "final_mean_rmse = np.sqrt(mean_squared_error(y_true, oof_mean_preds))\n",
    "print(f\"\\n# Mean model K-Fold training complete.\")\n",
    "print(f\"# Final OOF RMSE for Mean Model: ${final_mean_rmse:,.2f}\")\n",
    "print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f550b9d5-5536-4c37-b80e-7d4c097656df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Performing feature engineering for the error model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-08 20:30:37,301] A new study created in memory with name: no-name-3872e6ec-667b-44f4-903e-c33067709590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Adding 'mean_pred_oof' feature...\n",
      "  Adding 'pred_deviation' feature...\n",
      "  Adding 'pred_bin' feature...\n",
      "\n",
      "# Feature engineering complete. Total features for error model: 114\n",
      "\n",
      "# STAGE 2, PART 1: Tuning Error Prediction Model (on new features)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-08 20:30:48,738] Trial 0 finished with value: 63661.17282648306 and parameters: {'eta': 0.026973437442620693, 'max_depth': 9, 'subsample': 0.8669033717360423, 'colsample_bytree': 0.7064243155359198, 'lambda': 0.45082975488131105, 'alpha': 0.6614010449644007}. Best is trial 0 with value: 63661.17282648306.\n",
      "[I 2025-07-08 20:30:57,078] Trial 1 finished with value: 63629.1717687304 and parameters: {'eta': 0.0217760396484855, 'max_depth': 8, 'subsample': 0.8557787164397109, 'colsample_bytree': 0.7025573880523461, 'lambda': 0.5352732008016118, 'alpha': 0.6738595615124922}. Best is trial 1 with value: 63629.1717687304.\n",
      "[I 2025-07-08 20:31:03,431] Trial 2 finished with value: 63623.12536613408 and parameters: {'eta': 0.023543226235028355, 'max_depth': 7, 'subsample': 0.8386830490846758, 'colsample_bytree': 0.7408331517694875, 'lambda': 0.39967564093863556, 'alpha': 0.5284111696333488}. Best is trial 2 with value: 63623.12536613408.\n",
      "[I 2025-07-08 20:31:17,014] Trial 3 finished with value: 63542.50990007777 and parameters: {'eta': 0.016845525176448186, 'max_depth': 9, 'subsample': 0.9048379992984148, 'colsample_bytree': 0.7410739096594253, 'lambda': 0.4315591811048453, 'alpha': 0.5554143532669931}. Best is trial 3 with value: 63542.50990007777.\n",
      "[I 2025-07-08 20:31:34,540] Trial 4 finished with value: 63582.15993717371 and parameters: {'eta': 0.012066720048278506, 'max_depth': 9, 'subsample': 0.8065020966666894, 'colsample_bytree': 0.6949177652560222, 'lambda': 0.49391168548414965, 'alpha': 0.5471021304585981}. Best is trial 3 with value: 63542.50990007777.\n",
      "[I 2025-07-08 20:31:54,487] Trial 5 finished with value: 63658.94336967959 and parameters: {'eta': 0.010026986124882021, 'max_depth': 10, 'subsample': 0.898929768991392, 'colsample_bytree': 0.7306848205290226, 'lambda': 0.3701004147898283, 'alpha': 0.6309058905684967}. Best is trial 3 with value: 63542.50990007777.\n",
      "[I 2025-07-08 20:32:10,295] Trial 6 finished with value: 63469.38576954454 and parameters: {'eta': 0.012514565366903707, 'max_depth': 9, 'subsample': 0.9329243425999, 'colsample_bytree': 0.6959565650360771, 'lambda': 0.4459079150409732, 'alpha': 0.5472637169401509}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:32:21,173] Trial 7 finished with value: 63659.269142961275 and parameters: {'eta': 0.016221670962188548, 'max_depth': 8, 'subsample': 0.9039588122310126, 'colsample_bytree': 0.7155871107476004, 'lambda': 0.5198437757087665, 'alpha': 0.6011329629880697}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:32:27,361] Trial 8 finished with value: 63973.331607555985 and parameters: {'eta': 0.025733135808146852, 'max_depth': 10, 'subsample': 0.8180519455219689, 'colsample_bytree': 0.7490388352751378, 'lambda': 0.7568921719178132, 'alpha': 0.5794927132303337}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:32:37,689] Trial 9 finished with value: 63701.12003801302 and parameters: {'eta': 0.029666109873670035, 'max_depth': 9, 'subsample': 0.9521867077509868, 'colsample_bytree': 0.7387163168695812, 'lambda': 0.3706039622320262, 'alpha': 0.6543569978192529}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:32:51,030] Trial 10 finished with value: 63568.05532683763 and parameters: {'eta': 0.016481590982461825, 'max_depth': 7, 'subsample': 0.9806270822996375, 'colsample_bytree': 0.7195502783781216, 'lambda': 0.6291085443398561, 'alpha': 0.47863040689107866}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:33:02,339] Trial 11 finished with value: 63621.22125626389 and parameters: {'eta': 0.016475899464112948, 'max_depth': 9, 'subsample': 0.9332906657782043, 'colsample_bytree': 0.7288215471287948, 'lambda': 0.42781364460889415, 'alpha': 0.509590357883673}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:33:21,353] Trial 12 finished with value: 63663.886423282725 and parameters: {'eta': 0.013580414754360594, 'max_depth': 10, 'subsample': 0.9319338044845538, 'colsample_bytree': 0.7095958777470646, 'lambda': 0.45405847970723334, 'alpha': 0.5609729420668075}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:33:30,479] Trial 13 finished with value: 63591.83829784899 and parameters: {'eta': 0.018412274824336904, 'max_depth': 8, 'subsample': 0.9261511575292206, 'colsample_bytree': 0.6933706791735481, 'lambda': 0.34617415384543, 'alpha': 0.46372660962612067}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:33:46,665] Trial 14 finished with value: 63683.16574708507 and parameters: {'eta': 0.013626134421368272, 'max_depth': 9, 'subsample': 0.9772954216405473, 'colsample_bytree': 0.7274184896895116, 'lambda': 0.5675123660259689, 'alpha': 0.6008612611499105}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:33:53,991] Trial 15 finished with value: 63624.50013643915 and parameters: {'eta': 0.01959612035967484, 'max_depth': 8, 'subsample': 0.8786377095427527, 'colsample_bytree': 0.7476272324319605, 'lambda': 0.4234195721394731, 'alpha': 0.5065510228616136}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:34:19,770] Trial 16 finished with value: 63579.214392153845 and parameters: {'eta': 0.01059201147456142, 'max_depth': 10, 'subsample': 0.9119335426102411, 'colsample_bytree': 0.7361799813045484, 'lambda': 0.47836057207345145, 'alpha': 0.5840506381096532}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:34:35,188] Trial 17 finished with value: 63499.58875228664 and parameters: {'eta': 0.014311135072168593, 'max_depth': 9, 'subsample': 0.9485578500956887, 'colsample_bytree': 0.7147685650106727, 'lambda': 0.6118533770052096, 'alpha': 0.5397626207939885}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:34:48,896] Trial 18 finished with value: 63526.23499004984 and parameters: {'eta': 0.014018431747338968, 'max_depth': 8, 'subsample': 0.9601385168757037, 'colsample_bytree': 0.7002924137604278, 'lambda': 0.6585083772509406, 'alpha': 0.5290448043648581}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:35:09,684] Trial 19 finished with value: 63646.494805673836 and parameters: {'eta': 0.01206778376194086, 'max_depth': 10, 'subsample': 0.9535435707909472, 'colsample_bytree': 0.7132301196711467, 'lambda': 0.5825918985921531, 'alpha': 0.4936542430998156}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:35:22,432] Trial 20 finished with value: 63709.26153349754 and parameters: {'eta': 0.014756076239343793, 'max_depth': 9, 'subsample': 0.9606433239142382, 'colsample_bytree': 0.7221013556739964, 'lambda': 0.7232601169777757, 'alpha': 0.6288457541939828}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:35:33,187] Trial 21 finished with value: 63532.46002026197 and parameters: {'eta': 0.0142193263022573, 'max_depth': 8, 'subsample': 0.9635038026029813, 'colsample_bytree': 0.7004720364197341, 'lambda': 0.6790256939106102, 'alpha': 0.5336502485031086}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:35:48,775] Trial 22 finished with value: 63522.79199218718 and parameters: {'eta': 0.01186998703503044, 'max_depth': 7, 'subsample': 0.9423802392865613, 'colsample_bytree': 0.6980929561077345, 'lambda': 0.6353126449323592, 'alpha': 0.5249599761081836}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:36:03,803] Trial 23 finished with value: 63573.9161653449 and parameters: {'eta': 0.012076724588629259, 'max_depth': 7, 'subsample': 0.9356547239935187, 'colsample_bytree': 0.696887833661601, 'lambda': 0.6095344923525421, 'alpha': 0.5085231669863532}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:36:22,541] Trial 24 finished with value: 63551.191406871185 and parameters: {'eta': 0.011527354533890932, 'max_depth': 9, 'subsample': 0.9189510798524979, 'colsample_bytree': 0.7042988249068834, 'lambda': 0.5424488074467329, 'alpha': 0.5450103243918372}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:36:31,190] Trial 25 finished with value: 63569.43840294833 and parameters: {'eta': 0.018086115711556792, 'max_depth': 7, 'subsample': 0.9431951534256167, 'colsample_bytree': 0.7092096410137904, 'lambda': 0.6892991396642512, 'alpha': 0.5690952580345255}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:36:45,556] Trial 26 finished with value: 63584.378313912806 and parameters: {'eta': 0.012747997736478658, 'max_depth': 8, 'subsample': 0.976695211802332, 'colsample_bytree': 0.6978530342070254, 'lambda': 0.6221576933234504, 'alpha': 0.48886096563891585}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:36:56,285] Trial 27 finished with value: 63651.68343619585 and parameters: {'eta': 0.015458718777276009, 'max_depth': 9, 'subsample': 0.8861696302919307, 'colsample_bytree': 0.6922050445230052, 'lambda': 0.5753138342444677, 'alpha': 0.520316331855707}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:37:14,079] Trial 28 finished with value: 63533.93728413681 and parameters: {'eta': 0.010000869321945076, 'max_depth': 7, 'subsample': 0.9439214243135542, 'colsample_bytree': 0.7139723085358544, 'lambda': 0.50518257835742, 'alpha': 0.45834772852579475}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:37:22,047] Trial 29 finished with value: 63691.02118496595 and parameters: {'eta': 0.020916716450731065, 'max_depth': 9, 'subsample': 0.988596002822923, 'colsample_bytree': 0.7067801430496449, 'lambda': 0.6502082575653959, 'alpha': 0.5987877138562003}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:37:33,357] Trial 30 finished with value: 63667.796140067134 and parameters: {'eta': 0.01829315085644343, 'max_depth': 9, 'subsample': 0.9205155557394584, 'colsample_bytree': 0.7227951195278111, 'lambda': 0.4721069985449668, 'alpha': 0.5414591570065188}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:37:44,374] Trial 31 finished with value: 63606.66383026769 and parameters: {'eta': 0.013533612055486956, 'max_depth': 8, 'subsample': 0.9650336390095563, 'colsample_bytree': 0.7002588707301252, 'lambda': 0.6730304055977457, 'alpha': 0.5191634173213009}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:37:57,601] Trial 32 finished with value: 63505.5454935901 and parameters: {'eta': 0.014992938780918742, 'max_depth': 8, 'subsample': 0.947623807656916, 'colsample_bytree': 0.7035501284969111, 'lambda': 0.7072280751089024, 'alpha': 0.5625483192310289}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:38:10,232] Trial 33 finished with value: 63530.454463633185 and parameters: {'eta': 0.015349516305481354, 'max_depth': 7, 'subsample': 0.9448433584073308, 'colsample_bytree': 0.7048254228009628, 'lambda': 0.7253868050951393, 'alpha': 0.5647509583759056}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:38:20,490] Trial 34 finished with value: 63610.19263970393 and parameters: {'eta': 0.024051386690538815, 'max_depth': 8, 'subsample': 0.8522806327504513, 'colsample_bytree': 0.7087481701967667, 'lambda': 0.7147541521100931, 'alpha': 0.5855496911134503}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:38:38,861] Trial 35 finished with value: 63613.668462293725 and parameters: {'eta': 0.011201909884103857, 'max_depth': 7, 'subsample': 0.91623992570609, 'colsample_bytree': 0.6976027371031948, 'lambda': 0.5512016299234735, 'alpha': 0.5570209415918168}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:38:55,088] Trial 36 finished with value: 63591.88164615489 and parameters: {'eta': 0.012683358402585497, 'max_depth': 8, 'subsample': 0.9685329641272927, 'colsample_bytree': 0.7037515529981994, 'lambda': 0.6079661153603872, 'alpha': 0.548870501388895}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:39:10,163] Trial 37 finished with value: 63542.51723030133 and parameters: {'eta': 0.015181627091233003, 'max_depth': 9, 'subsample': 0.9486143703803854, 'colsample_bytree': 0.7184139079419258, 'lambda': 0.7531290647690361, 'alpha': 0.5335884870835128}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:39:27,236] Trial 38 finished with value: 63542.458620929545 and parameters: {'eta': 0.012927453989970191, 'max_depth': 7, 'subsample': 0.8884412360185838, 'colsample_bytree': 0.69591417689269, 'lambda': 0.39855562418570234, 'alpha': 0.5210669552905578}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:39:40,786] Trial 39 finished with value: 63625.48226375089 and parameters: {'eta': 0.01729978904930483, 'max_depth': 9, 'subsample': 0.9031389328100013, 'colsample_bytree': 0.7115452929319585, 'lambda': 0.6408601105616808, 'alpha': 0.5721378834106523}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:39:54,863] Trial 40 finished with value: 63484.420353893765 and parameters: {'eta': 0.01919524640083244, 'max_depth': 10, 'subsample': 0.937077835434139, 'colsample_bytree': 0.7163399618375952, 'lambda': 0.5216233496789311, 'alpha': 0.6128234922123089}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:40:06,299] Trial 41 finished with value: 63697.54887146225 and parameters: {'eta': 0.020013517482470086, 'max_depth': 10, 'subsample': 0.9388007657773202, 'colsample_bytree': 0.7163734968629952, 'lambda': 0.5309766953485671, 'alpha': 0.6255885759693087}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:40:18,385] Trial 42 finished with value: 63734.40640359636 and parameters: {'eta': 0.02185005625861634, 'max_depth': 10, 'subsample': 0.9265430155139863, 'colsample_bytree': 0.7246563899050705, 'lambda': 0.4499927321185064, 'alpha': 0.6719996227078195}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:40:29,859] Trial 43 finished with value: 63763.836396442995 and parameters: {'eta': 0.023000614263375973, 'max_depth': 10, 'subsample': 0.95340223839227, 'colsample_bytree': 0.7066792987125687, 'lambda': 0.5902950293792191, 'alpha': 0.6173855083700021}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:40:37,509] Trial 44 finished with value: 63745.140110063825 and parameters: {'eta': 0.027107328334135875, 'max_depth': 10, 'subsample': 0.9089625776507847, 'colsample_bytree': 0.7010335676001007, 'lambda': 0.40755336600308445, 'alpha': 0.6415360192092852}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:40:49,829] Trial 45 finished with value: 63591.57462959734 and parameters: {'eta': 0.017313733230575053, 'max_depth': 9, 'subsample': 0.9249549693246674, 'colsample_bytree': 0.6948324628132175, 'lambda': 0.700011176514962, 'alpha': 0.5547790639426594}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:41:08,497] Trial 46 finished with value: 63526.91656983109 and parameters: {'eta': 0.010945600738833772, 'max_depth': 8, 'subsample': 0.974121272729309, 'colsample_bytree': 0.7181374188395813, 'lambda': 0.5165932301557491, 'alpha': 0.6145088407115379}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:41:23,663] Trial 47 finished with value: 63603.400192050045 and parameters: {'eta': 0.01613418206902612, 'max_depth': 9, 'subsample': 0.9343894047829184, 'colsample_bytree': 0.7339244061620064, 'lambda': 0.5019246582172776, 'alpha': 0.5942851235656782}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:41:36,092] Trial 48 finished with value: 63653.80376374358 and parameters: {'eta': 0.0195407937938575, 'max_depth': 10, 'subsample': 0.8970045670205692, 'colsample_bytree': 0.7120273891640112, 'lambda': 0.5573011338356105, 'alpha': 0.6851812216381988}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:41:46,786] Trial 49 finished with value: 63564.60341812461 and parameters: {'eta': 0.014711139953050541, 'max_depth': 8, 'subsample': 0.9552730103590832, 'colsample_bytree': 0.6984462807234854, 'lambda': 0.48507343975366984, 'alpha': 0.5422015939795783}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:42:02,913] Trial 50 finished with value: 63596.97448434663 and parameters: {'eta': 0.013099044090619674, 'max_depth': 9, 'subsample': 0.8016358812873414, 'colsample_bytree': 0.702798914807506, 'lambda': 0.453857637810087, 'alpha': 0.576615202513626}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:42:16,886] Trial 51 finished with value: 63564.35189324249 and parameters: {'eta': 0.01401778786642009, 'max_depth': 8, 'subsample': 0.9589928102081324, 'colsample_bytree': 0.6937210060818093, 'lambda': 0.6587793612644207, 'alpha': 0.5330476627173711}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:42:29,520] Trial 52 finished with value: 63627.828980229926 and parameters: {'eta': 0.011897522589493812, 'max_depth': 8, 'subsample': 0.9874262073877349, 'colsample_bytree': 0.7002252745958166, 'lambda': 0.603017857597947, 'alpha': 0.4974808478336841}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:42:43,557] Trial 53 finished with value: 63469.50805124217 and parameters: {'eta': 0.015912797077012174, 'max_depth': 8, 'subsample': 0.9391925515188592, 'colsample_bytree': 0.7056775990900463, 'lambda': 0.6649293542690143, 'alpha': 0.528487401176524}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:42:57,121] Trial 54 finished with value: 63521.02004769387 and parameters: {'eta': 0.015988301308984796, 'max_depth': 8, 'subsample': 0.9303351848654673, 'colsample_bytree': 0.7070251095988058, 'lambda': 0.6245555923596515, 'alpha': 0.5143062805707019}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:43:11,091] Trial 55 finished with value: 63490.38254198794 and parameters: {'eta': 0.015870241643969923, 'max_depth': 8, 'subsample': 0.9303339498713663, 'colsample_bytree': 0.7106093658279721, 'lambda': 0.7403803890642358, 'alpha': 0.48027424104890054}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:43:23,689] Trial 56 finished with value: 63606.17684023521 and parameters: {'eta': 0.017160775300234434, 'max_depth': 8, 'subsample': 0.9494435473408613, 'colsample_bytree': 0.7105084718803547, 'lambda': 0.7556450334136784, 'alpha': 0.4756539113976263}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:43:36,361] Trial 57 finished with value: 63649.43766710076 and parameters: {'eta': 0.015819318790543012, 'max_depth': 8, 'subsample': 0.8301892100325026, 'colsample_bytree': 0.7158874035282137, 'lambda': 0.7420633349045455, 'alpha': 0.47347826203592497}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:43:48,465] Trial 58 finished with value: 63642.45746743208 and parameters: {'eta': 0.01461170608940401, 'max_depth': 8, 'subsample': 0.9706982877709915, 'colsample_bytree': 0.7197437116261414, 'lambda': 0.6752933267044633, 'alpha': 0.589353225007859}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:43:59,610] Trial 59 finished with value: 63551.23897434997 and parameters: {'eta': 0.017885944599056337, 'max_depth': 9, 'subsample': 0.9137771350505546, 'colsample_bytree': 0.7140840476805, 'lambda': 0.7052149599233478, 'alpha': 0.6098448677145927}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:44:08,441] Trial 60 finished with value: 63585.93546612949 and parameters: {'eta': 0.019327286323396253, 'max_depth': 8, 'subsample': 0.9381818777367422, 'colsample_bytree': 0.7085542744733694, 'lambda': 0.3813758541893467, 'alpha': 0.49890032807427254}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:44:17,866] Trial 61 finished with value: 63619.16741830114 and parameters: {'eta': 0.016553506422893504, 'max_depth': 8, 'subsample': 0.929430726071215, 'colsample_bytree': 0.7057513042242445, 'lambda': 0.625799032031794, 'alpha': 0.4871153113882425}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:44:29,921] Trial 62 finished with value: 63572.98501249463 and parameters: {'eta': 0.01893552535655017, 'max_depth': 8, 'subsample': 0.9216221638554652, 'colsample_bytree': 0.7069501204961735, 'lambda': 0.7352472520470262, 'alpha': 0.5118336162405654}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:44:44,268] Trial 63 finished with value: 63527.64439579694 and parameters: {'eta': 0.016145647678713033, 'max_depth': 8, 'subsample': 0.9284027194511958, 'colsample_bytree': 0.7131575255051872, 'lambda': 0.6960568930567332, 'alpha': 0.5505037833352189}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:44:57,882] Trial 64 finished with value: 63558.445105388135 and parameters: {'eta': 0.015075591936963584, 'max_depth': 8, 'subsample': 0.9354964803580933, 'colsample_bytree': 0.7022271162480148, 'lambda': 0.7645794374612221, 'alpha': 0.5614288452365235}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:45:14,547] Trial 65 finished with value: 63533.62678513479 and parameters: {'eta': 0.014266317201005883, 'max_depth': 9, 'subsample': 0.9456211254012479, 'colsample_bytree': 0.7080247433423786, 'lambda': 0.6665875103541768, 'alpha': 0.5386542319822185}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:45:26,290] Trial 66 finished with value: 63565.846533169766 and parameters: {'eta': 0.01569805390574233, 'max_depth': 8, 'subsample': 0.9575825272020511, 'colsample_bytree': 0.7111490667832908, 'lambda': 0.6818326958817965, 'alpha': 0.5129770534343521}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:45:34,518] Trial 67 finished with value: 63573.04280252265 and parameters: {'eta': 0.02037366824757496, 'max_depth': 8, 'subsample': 0.9076697888053813, 'colsample_bytree': 0.7169269592484506, 'lambda': 0.6499244600046287, 'alpha': 0.5038377477677494}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:45:46,397] Trial 68 finished with value: 63696.835041567036 and parameters: {'eta': 0.013530999254909078, 'max_depth': 9, 'subsample': 0.869566788041817, 'colsample_bytree': 0.7452309302728073, 'lambda': 0.34567055437834454, 'alpha': 0.5270617423251807}. Best is trial 6 with value: 63469.38576954454.\n",
      "[I 2025-07-08 20:45:59,237] Trial 69 finished with value: 63440.508427118206 and parameters: {'eta': 0.016646471543381575, 'max_depth': 8, 'subsample': 0.9400305830327599, 'colsample_bytree': 0.704823223480978, 'lambda': 0.43787910646980066, 'alpha': 0.5664456910328979}. Best is trial 69 with value: 63440.508427118206.\n",
      "[I 2025-07-08 20:46:13,177] Trial 70 finished with value: 63611.59289487338 and parameters: {'eta': 0.016685402668373386, 'max_depth': 9, 'subsample': 0.9391619187520283, 'colsample_bytree': 0.714384920882313, 'lambda': 0.4145881040141431, 'alpha': 0.5777008726086112}. Best is trial 69 with value: 63440.508427118206.\n",
      "[I 2025-07-08 20:46:25,199] Trial 71 finished with value: 63478.90036795572 and parameters: {'eta': 0.017718289336265604, 'max_depth': 8, 'subsample': 0.9314651499307255, 'colsample_bytree': 0.703731034625435, 'lambda': 0.4660975386900866, 'alpha': 0.5540583799046234}. Best is trial 69 with value: 63440.508427118206.\n",
      "[I 2025-07-08 20:46:35,329] Trial 72 finished with value: 63621.079167604774 and parameters: {'eta': 0.017874199210015703, 'max_depth': 8, 'subsample': 0.9497975875864226, 'colsample_bytree': 0.7043732220425074, 'lambda': 0.44655474523485394, 'alpha': 0.5652286192516471}. Best is trial 69 with value: 63440.508427118206.\n",
      "[I 2025-07-08 20:46:43,772] Trial 73 finished with value: 63661.8940387365 and parameters: {'eta': 0.018479563087454878, 'max_depth': 8, 'subsample': 0.9220040321622983, 'colsample_bytree': 0.7019374253697693, 'lambda': 0.4727882098524128, 'alpha': 0.5677769806493966}. Best is trial 69 with value: 63440.508427118206.\n",
      "[I 2025-07-08 20:46:54,872] Trial 74 finished with value: 63538.14063333081 and parameters: {'eta': 0.017535926851272268, 'max_depth': 8, 'subsample': 0.9416891820169995, 'colsample_bytree': 0.7100704913062215, 'lambda': 0.4671388335014033, 'alpha': 0.5544473536551164}. Best is trial 69 with value: 63440.508427118206.\n",
      "[I 2025-07-08 20:47:04,475] Trial 75 finished with value: 63597.42761709113 and parameters: {'eta': 0.01690990682923669, 'max_depth': 8, 'subsample': 0.964911737282678, 'colsample_bytree': 0.6989918192091167, 'lambda': 0.4338164822532775, 'alpha': 0.6476945729064754}. Best is trial 69 with value: 63440.508427118206.\n",
      "[I 2025-07-08 20:47:15,035] Trial 76 finished with value: 63609.248707790786 and parameters: {'eta': 0.01876199228376623, 'max_depth': 8, 'subsample': 0.9338294202415248, 'colsample_bytree': 0.7051653586241654, 'lambda': 0.43300157009367557, 'alpha': 0.5466766307035541}. Best is trial 69 with value: 63440.508427118206.\n",
      "[I 2025-07-08 20:47:25,850] Trial 77 finished with value: 63708.55711782316 and parameters: {'eta': 0.020867718719278165, 'max_depth': 10, 'subsample': 0.9166873696514779, 'colsample_bytree': 0.703351910543683, 'lambda': 0.38838767715896694, 'alpha': 0.5820174070955412}. Best is trial 69 with value: 63440.508427118206.\n",
      "[I 2025-07-08 20:47:40,479] Trial 78 finished with value: 63570.81527963946 and parameters: {'eta': 0.015342215354153293, 'max_depth': 7, 'subsample': 0.9468068357978492, 'colsample_bytree': 0.7122748517568677, 'lambda': 0.4889818192932451, 'alpha': 0.5392137580423836}. Best is trial 69 with value: 63440.508427118206.\n",
      "[I 2025-07-08 20:47:55,697] Trial 79 finished with value: 63542.84731184578 and parameters: {'eta': 0.012323982207092781, 'max_depth': 8, 'subsample': 0.9531787036787821, 'colsample_bytree': 0.7246762133395329, 'lambda': 0.44429910074718293, 'alpha': 0.5594262538272126}. Best is trial 69 with value: 63440.508427118206.\n",
      "[I 2025-07-08 20:48:08,325] Trial 80 finished with value: 63584.08797336996 and parameters: {'eta': 0.014504957902051741, 'max_depth': 9, 'subsample': 0.9245913121825746, 'colsample_bytree': 0.6961255474303772, 'lambda': 0.4596601678899405, 'alpha': 0.5701403802969388}. Best is trial 69 with value: 63440.508427118206.\n",
      "[I 2025-07-08 20:48:20,322] Trial 81 finished with value: 63588.88888323713 and parameters: {'eta': 0.01599088902468155, 'max_depth': 8, 'subsample': 0.9300927426119989, 'colsample_bytree': 0.7059176125853629, 'lambda': 0.41946662956379305, 'alpha': 0.5196341118584359}. Best is trial 69 with value: 63440.508427118206.\n",
      "[I 2025-07-08 20:48:34,016] Trial 82 finished with value: 63502.85878168123 and parameters: {'eta': 0.013750039453944731, 'max_depth': 8, 'subsample': 0.9335737179833369, 'colsample_bytree': 0.7073858657190236, 'lambda': 0.712662684717797, 'alpha': 0.4655551741743395}. Best is trial 69 with value: 63440.508427118206.\n",
      "[I 2025-07-08 20:48:48,642] Trial 83 finished with value: 63491.38086132944 and parameters: {'eta': 0.013425655669449171, 'max_depth': 8, 'subsample': 0.9424610256022202, 'colsample_bytree': 0.7094304120163981, 'lambda': 0.71734360618765, 'alpha': 0.45642499124809366}. Best is trial 69 with value: 63440.508427118206.\n",
      "[I 2025-07-08 20:49:04,152] Trial 84 finished with value: 63526.800431613476 and parameters: {'eta': 0.013327812371318058, 'max_depth': 8, 'subsample': 0.938917481021949, 'colsample_bytree': 0.7081755038271375, 'lambda': 0.7181574682455999, 'alpha': 0.46303247083008753}. Best is trial 69 with value: 63440.508427118206.\n",
      "[I 2025-07-08 20:49:23,282] Trial 85 finished with value: 63523.96506498689 and parameters: {'eta': 0.013797067985122063, 'max_depth': 8, 'subsample': 0.9416948638529551, 'colsample_bytree': 0.7148950434806535, 'lambda': 0.7432606013130129, 'alpha': 0.4564625529330275}. Best is trial 69 with value: 63440.508427118206.\n",
      "[I 2025-07-08 20:49:36,644] Trial 86 finished with value: 63558.692030947095 and parameters: {'eta': 0.012474121821391005, 'max_depth': 8, 'subsample': 0.9360386168594463, 'colsample_bytree': 0.7205096866287297, 'lambda': 0.7271614121874376, 'alpha': 0.4674471627338632}. Best is trial 69 with value: 63440.508427118206.\n",
      "[I 2025-07-08 20:49:59,233] Trial 87 finished with value: 63652.38747885146 and parameters: {'eta': 0.011274127884550799, 'max_depth': 10, 'subsample': 0.9185285489547822, 'colsample_bytree': 0.7096910652520138, 'lambda': 0.44032562826604527, 'alpha': 0.48732294801423337}. Best is trial 69 with value: 63440.508427118206.\n",
      "[I 2025-07-08 20:50:15,077] Trial 88 finished with value: 63586.04667169174 and parameters: {'eta': 0.012969564310358027, 'max_depth': 8, 'subsample': 0.9033250769312317, 'colsample_bytree': 0.717987381174023, 'lambda': 0.6907462832510022, 'alpha': 0.4813714966682629}. Best is trial 69 with value: 63440.508427118206.\n",
      "[I 2025-07-08 20:50:32,325] Trial 89 finished with value: 63486.78907305079 and parameters: {'eta': 0.010664509947427963, 'max_depth': 9, 'subsample': 0.9321239387485397, 'colsample_bytree': 0.7128969811596011, 'lambda': 0.5008290616081277, 'alpha': 0.4679645661988073}. Best is trial 69 with value: 63440.508427118206.\n",
      "[I 2025-07-08 20:50:51,086] Trial 90 finished with value: 63492.89764460484 and parameters: {'eta': 0.010607710419903566, 'max_depth': 9, 'subsample': 0.9120570084269711, 'colsample_bytree': 0.7127110328869749, 'lambda': 0.5044673983037428, 'alpha': 0.5519975451016301}. Best is trial 69 with value: 63440.508427118206.\n",
      "[I 2025-07-08 20:51:06,774] Trial 91 finished with value: 63537.31001719531 and parameters: {'eta': 0.010259423546564627, 'max_depth': 9, 'subsample': 0.9253039702740519, 'colsample_bytree': 0.713102778031052, 'lambda': 0.4952248987043891, 'alpha': 0.47235096718963643}. Best is trial 69 with value: 63440.508427118206.\n",
      "[I 2025-07-08 20:51:21,949] Trial 92 finished with value: 63483.715924718395 and parameters: {'eta': 0.010488805625260625, 'max_depth': 9, 'subsample': 0.9094335363169511, 'colsample_bytree': 0.7109633033478319, 'lambda': 0.5256570714136585, 'alpha': 0.4806983610258918}. Best is trial 69 with value: 63440.508427118206.\n",
      "[I 2025-07-08 20:51:40,773] Trial 93 finished with value: 63458.284760410825 and parameters: {'eta': 0.010521329021058725, 'max_depth': 9, 'subsample': 0.8905947723910297, 'colsample_bytree': 0.7111397236577777, 'lambda': 0.5248251887399, 'alpha': 0.48326584107175186}. Best is trial 69 with value: 63440.508427118206.\n",
      "[I 2025-07-08 20:51:54,147] Trial 94 finished with value: 63584.69677020721 and parameters: {'eta': 0.01148462046129569, 'max_depth': 9, 'subsample': 0.8928435869675985, 'colsample_bytree': 0.7106866520864656, 'lambda': 0.5264199571500454, 'alpha': 0.4818476981979371}. Best is trial 69 with value: 63440.508427118206.\n",
      "[I 2025-07-08 20:52:07,616] Trial 95 finished with value: 63579.99480267505 and parameters: {'eta': 0.010479950511913954, 'max_depth': 9, 'subsample': 0.8850619678496316, 'colsample_bytree': 0.7090586639068461, 'lambda': 0.5413367777970546, 'alpha': 0.46022550950522567}. Best is trial 69 with value: 63440.508427118206.\n",
      "[I 2025-07-08 20:52:26,186] Trial 96 finished with value: 63544.29216964803 and parameters: {'eta': 0.010920348356001442, 'max_depth': 9, 'subsample': 0.8943730659026604, 'colsample_bytree': 0.7116867999011489, 'lambda': 0.5161213896151635, 'alpha': 0.4719596725632937}. Best is trial 69 with value: 63440.508427118206.\n",
      "[I 2025-07-08 20:52:43,704] Trial 97 finished with value: 63540.60810869781 and parameters: {'eta': 0.011685727802982283, 'max_depth': 9, 'subsample': 0.8778691082932192, 'colsample_bytree': 0.7154793848867232, 'lambda': 0.4663361790875613, 'alpha': 0.4924235790235367}. Best is trial 69 with value: 63440.508427118206.\n",
      "[I 2025-07-08 20:53:02,729] Trial 98 finished with value: 63557.5425219399 and parameters: {'eta': 0.010983143020156103, 'max_depth': 9, 'subsample': 0.94236371901224, 'colsample_bytree': 0.7171904995138958, 'lambda': 0.48164962465134653, 'alpha': 0.4555507413382543}. Best is trial 69 with value: 63440.508427118206.\n",
      "[I 2025-07-08 20:53:18,918] Trial 99 finished with value: 63511.84964031662 and parameters: {'eta': 0.010176297321042834, 'max_depth': 9, 'subsample': 0.931406233354657, 'colsample_bytree': 0.7095202202122235, 'lambda': 0.5640083942062262, 'alpha': 0.47813012375903424}. Best is trial 69 with value: 63440.508427118206.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Error Model Tuning Complete. Best Validation RMSE: $63,440.51\n",
      "\n",
      "# STAGE 2, PART 2: K-Fold Training of Error Model...\n",
      "  Error Model - Fold 1/5...\n",
      "  Error Model - Fold 2/5...\n",
      "  Error Model - Fold 3/5...\n",
      "  Error Model - Fold 4/5...\n",
      "  Error Model - Fold 5/5...\n",
      "\n",
      "# Error model K-Fold training complete.\n",
      "# Final OOF RMSE for Error Model: $62,866.29\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STAGE 2: ERROR MODEL FEATURE ENGINEERING, TUNING, AND TRAINING\n",
    "# =============================================================================\n",
    "\n",
    "# --- Define the Error Target ---\n",
    "error_target = np.abs(y_true - oof_mean_preds)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# --- PART 1A: FEATURE ENGINEERING FOR THE ERROR MODEL ---\n",
    "# =============================================================================\n",
    "print(\"\\n# Performing feature engineering for the error model...\")\n",
    "\n",
    "# Start with copies of the original data\n",
    "X_for_error = X.copy()\n",
    "X_test_for_error = X_test.copy()\n",
    "\n",
    "# Feature 1: The mean prediction itself\n",
    "print(\"  Adding 'mean_pred_oof' feature...\")\n",
    "X_for_error['mean_pred_oof'] = oof_mean_preds\n",
    "X_test_for_error['mean_pred_oof'] = test_mean_preds\n",
    "\n",
    "# Feature 2: Deviation from the average prediction\n",
    "print(\"  Adding 'pred_deviation' feature...\")\n",
    "avg_oof_pred = oof_mean_preds.mean()\n",
    "X_for_error['pred_deviation'] = np.abs(X_for_error['mean_pred_oof'] - avg_oof_pred)\n",
    "X_test_for_error['pred_deviation'] = np.abs(X_test_for_error['mean_pred_oof'] - avg_oof_pred)\n",
    "\n",
    "# Feature 3: Binned predictions\n",
    "print(\"  Adding 'pred_bin' feature...\")\n",
    "X_for_error['pred_bin'], bin_edges = pd.qcut(X_for_error['mean_pred_oof'], \n",
    "                                             q=10, \n",
    "                                             labels=False, \n",
    "                                             retbins=True, \n",
    "                                             duplicates='drop')\n",
    "X_test_for_error['pred_bin'] = pd.cut(X_test_for_error['mean_pred_oof'], \n",
    "                                      bins=bin_edges, \n",
    "                                      labels=False, \n",
    "                                      include_lowest=True).fillna(-1).astype(int)\n",
    "\n",
    "print(f\"\\n# Feature engineering complete. Total features for error model: {X_for_error.shape[1]}\")\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "# --- PART 1B: Tuning the Error Model on the NEW Feature Set ---\n",
    "print(\"\\n# STAGE 2, PART 1: Tuning Error Prediction Model (on new features)...\")\n",
    "N_OPTUNA_TRIALS = 100\n",
    "\n",
    "def objective_error(trial):\n",
    "    # This split now correctly uses X_for_error which has the new features\n",
    "    train_x, val_x, train_y, val_y = train_test_split(X_for_error, error_target, test_size=0.2, random_state=RANDOM_STATE)\n",
    "    \n",
    "    params = {\n",
    "            'objective': 'reg:squarederror',\n",
    "            'eval_metric': 'rmse',\n",
    "            'tree_method': 'hist',\n",
    "            'eta': trial.suggest_float('eta', 0.01, 0.03),\n",
    "            'max_depth': trial.suggest_int('max_depth', 7, 10),\n",
    "            'subsample': trial.suggest_float('subsample', 0.8, 0.99),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.692, 0.75),\n",
    "            'lambda': trial.suggest_float('lambda', 0.345, 0.765, log=True),\n",
    "            'alpha': trial.suggest_float('alpha', 0.455, 0.69),\n",
    "        }\n",
    "\n",
    "    model = xgb.XGBRegressor(**params, n_estimators=2500, random_state=RANDOM_STATE, n_jobs=-1, early_stopping_rounds=100)\n",
    "    model.fit(train_x, train_y, eval_set=[(val_x, val_y)], verbose=False)\n",
    "    preds = model.predict(val_x)\n",
    "    return np.sqrt(mean_squared_error(val_y, preds))\n",
    "\n",
    "study_error = optuna.create_study(direction='minimize')\n",
    "study_error.optimize(objective_error, n_trials=N_OPTUNA_TRIALS)\n",
    "best_params_error = study_error.best_params\n",
    "print(f\"\\n# Error Model Tuning Complete. Best Validation RMSE: ${study_error.best_value:,.2f}\")\n",
    "\n",
    "\n",
    "# --- PART 2: K-Fold Training of Error Model with Best Params ---\n",
    "print(\"\\n# STAGE 2, PART 2: K-Fold Training of Error Model...\")\n",
    "oof_error_preds = np.zeros(len(X))\n",
    "test_error_preds = np.zeros(len(X_test))\n",
    "\n",
    "# Add the other required XGBoost parameters\n",
    "final_params_error = {\n",
    "    'objective': 'reg:squarederror', \n",
    "    'eval_metric': 'rmse',\n",
    "    'tree_method': 'hist', \n",
    "    'random_state': RANDOM_STATE, \n",
    "    'n_jobs': -1, \n",
    "    **best_params_error\n",
    "}\n",
    "\n",
    "# This loop now uses X_for_error, which has the correct features\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_for_error, grade_for_stratify)):\n",
    "    print(f\"  Error Model - Fold {fold+1}/{N_SPLITS}...\")\n",
    "    model = xgb.XGBRegressor(**final_params_error, n_estimators=2500, early_stopping_rounds=100)\n",
    "    \n",
    "    X_train, X_val = X_for_error.iloc[train_idx], X_for_error.iloc[val_idx]\n",
    "    y_train, y_val = error_target.iloc[train_idx], error_target.iloc[val_idx]\n",
    "    \n",
    "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "    \n",
    "    oof_error_preds[val_idx] = model.predict(X_val)\n",
    "    test_error_preds += model.predict(X_test_for_error) / N_SPLITS\n",
    "\n",
    "# --- Calculate and Print Final OOF RMSE ---\n",
    "final_error_rmse = np.sqrt(mean_squared_error(error_target, oof_error_preds))\n",
    "print(f\"\\n# Error model K-Fold training complete.\")\n",
    "print(f\"# Final OOF RMSE for Error Model: ${final_error_rmse:,.2f}\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce482100-97d5-486a-97e4-21e8a6acc805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Asymmetric Calibration ---\n",
      "New Best! a=1.90, b=2.10, Score=303,504.11, Cov=88.87%\n",
      "New Best! a=1.90, b=2.11, Score=303,453.51, Cov=88.94%\n",
      "New Best! a=1.90, b=2.12, Score=303,410.44, Cov=89.01%\n",
      "New Best! a=1.90, b=2.13, Score=303,373.20, Cov=89.07%\n",
      "New Best! a=1.90, b=2.14, Score=303,343.97, Cov=89.13%\n",
      "New Best! a=1.90, b=2.15, Score=303,321.27, Cov=89.20%\n",
      "New Best! a=1.90, b=2.16, Score=303,305.99, Cov=89.25%\n",
      "New Best! a=1.90, b=2.17, Score=303,297.62, Cov=89.32%\n",
      "New Best! a=1.90, b=2.18, Score=303,297.02, Cov=89.39%\n",
      "New Best! a=1.91, b=2.15, Score=303,277.68, Cov=89.29%\n",
      "New Best! a=1.91, b=2.16, Score=303,262.39, Cov=89.35%\n",
      "New Best! a=1.91, b=2.17, Score=303,254.03, Cov=89.41%\n",
      "New Best! a=1.91, b=2.18, Score=303,253.43, Cov=89.48%\n",
      "New Best! a=1.92, b=2.15, Score=303,244.07, Cov=89.38%\n",
      "New Best! a=1.92, b=2.16, Score=303,228.78, Cov=89.44%\n",
      "New Best! a=1.92, b=2.17, Score=303,220.42, Cov=89.50%\n",
      "New Best! a=1.92, b=2.18, Score=303,219.82, Cov=89.57%\n",
      "New Best! a=1.93, b=2.16, Score=303,205.57, Cov=89.53%\n",
      "New Best! a=1.93, b=2.17, Score=303,197.20, Cov=89.59%\n",
      "New Best! a=1.93, b=2.18, Score=303,196.61, Cov=89.66%\n",
      "New Best! a=1.94, b=2.16, Score=303,190.53, Cov=89.60%\n",
      "New Best! a=1.94, b=2.17, Score=303,182.16, Cov=89.66%\n",
      "New Best! a=1.94, b=2.18, Score=303,181.56, Cov=89.73%\n",
      "New Best! a=1.95, b=2.17, Score=303,175.79, Cov=89.75%\n",
      "New Best! a=1.95, b=2.18, Score=303,175.19, Cov=89.82%\n",
      "\n",
      "Grid search complete. Final OOF Score: 303,175.19. Best multipliers: a=1.95, b=2.18\n",
      "\n",
      "Creating final submission file...\n",
      "\n",
      "'submission_final_v6.csv' created successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pi_lower</th>\n",
       "      <th>pi_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200000</td>\n",
       "      <td>823019.231494</td>\n",
       "      <td>1.038293e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200001</td>\n",
       "      <td>595938.938379</td>\n",
       "      <td>8.168840e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200002</td>\n",
       "      <td>446821.759375</td>\n",
       "      <td>6.565207e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200003</td>\n",
       "      <td>277557.264868</td>\n",
       "      <td>4.030370e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200004</td>\n",
       "      <td>338362.155762</td>\n",
       "      <td>8.094089e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id       pi_lower      pi_upper\n",
       "0  200000  823019.231494  1.038293e+06\n",
       "1  200001  595938.938379  8.168840e+05\n",
       "2  200002  446821.759375  6.565207e+05\n",
       "3  200003  277557.264868  4.030370e+05\n",
       "4  200004  338362.155762  8.094089e+05"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# FINAL ASYMMETRIC CALIBRATION AND SUBMISSION (ULTIMATE ROBUST VERSION)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n--- Final Asymmetric Calibration ---\")\n",
    "\n",
    "# --- Safely reload y_true to ensure it's available ---\n",
    "y_true = pd.read_csv('./dataset.csv')['sale_price']\n",
    "\n",
    "# --- Your existing correct code ---\n",
    "oof_error_final = np.clip(oof_error_preds, 0, None) \n",
    "best_a, best_b, best_metric = 2.0, 2.0, float('inf')\n",
    "\n",
    "for a in np.arange(1.90, 2.31, 0.01):\n",
    "    for b in np.arange(2.10, 2.51, 0.01):\n",
    "        low = oof_mean_preds - oof_error_final * a\n",
    "        high = oof_mean_preds + oof_error_final * b\n",
    "        # We need the winkler_score function defined here or in a previous cell\n",
    "        metric, coverage = winkler_score(y_true, low, high, alpha=COMPETITION_ALPHA, return_coverage=True)\n",
    "        if metric < best_metric:\n",
    "            best_metric = metric\n",
    "            best_a, best_b = a, b\n",
    "            print(f\"New Best! a={best_a:.2f}, b={best_b:.2f}, Score={best_metric:,.2f}, Cov={coverage:.2%}\")\n",
    "print(f\"\\nGrid search complete. Final OOF Score: {best_metric:,.2f}. Best multipliers: a={best_a:.2f}, b={best_b:.2f}\")\n",
    "\n",
    "\n",
    "# --- Create Final Submission ---\n",
    "print(\"\\nCreating final submission file...\")\n",
    "test_error_final = np.clip(test_error_preds, 0, None)\n",
    "final_lower = test_mean_preds - test_error_final * best_a\n",
    "final_upper = test_mean_preds + test_error_final * best_b\n",
    "final_upper = np.maximum(final_lower, final_upper)\n",
    "\n",
    "# Your excellent, robust fix for the IDs\n",
    "test_ids = pd.read_csv('./test.csv', usecols=['id'])['id']\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_ids, \n",
    "    'pi_lower': final_lower, \n",
    "    'pi_upper': final_upper\n",
    "})\n",
    "\n",
    "submission_df.to_csv('submission_final_v6.csv', index=False)\n",
    "print(\"\\n'submission_final_v6.csv' created successfully!\")\n",
    "display(submission_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30da0c3-b4bf-4b77-9159-18723114fd98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Kaggle Comp)",
   "language": "python",
   "name": "kaggle-comp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
